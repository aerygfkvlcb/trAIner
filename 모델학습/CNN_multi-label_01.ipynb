{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d2e7f1-5c3f-48d2-9fc9-da7203c63a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be0c880-cc8c-4335-8f0c-1b3224abef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7874 7874\n",
      "1691 1691\n",
      "1687 1687\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "last_path = [[0,0,0],[1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,1],[1,0,1],[1,1,1]]\n",
    "prefix = [f\"{i:03d}\" for i in range(505, 513)]\n",
    "prefix_to_label = dict(zip(prefix, last_path))\n",
    "\n",
    "def process_dataset(root_folder):\n",
    "    image_paths = []\n",
    "    label_data = []\n",
    "\n",
    "    for roots, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                # 파일 이름 분석을 위해 숫자만 추출\n",
    "                prefix = file[0:3]\n",
    "                \n",
    "                # 접두사에 따른 레이블 할당\n",
    "                label = prefix_to_label.get(prefix)\n",
    "                \n",
    "                # 유효한 레이블이 있는 경우에만 리스트에 추가\n",
    "                if label is not None:\n",
    "                    image_paths.append(os.path.join(roots, file))\n",
    "                    label_data.append(label)\n",
    "    \n",
    "    return image_paths, label_data\n",
    "\n",
    "# 각각의 데이터셋에 대해 함수를 호출\n",
    "train_folder = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\training'\n",
    "valid_folder = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\validation'\n",
    "test_folder = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\test'\n",
    "\n",
    "train_image_paths, train_label_data = process_dataset(train_folder)\n",
    "valid_image_paths, valid_label_data = process_dataset(valid_folder)\n",
    "test_image_paths, test_label_data = process_dataset(test_folder)\n",
    "\n",
    "# 필요에 따라 결과를 확인하거나 다른 처리를 수행\n",
    "print(len(train_image_paths), len(train_label_data))\n",
    "print(len(valid_image_paths), len(valid_label_data))\n",
    "print(len(test_image_paths), len(test_label_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b87277-a1ac-47bf-80e9-a89fc97f0b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "def resize_img(image_paths):\n",
    "    images_resized = []  # 리사이즈된 이미지를 저장할 리스트\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)  # 각 이미지 경로로부터 이미지를 읽음\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR에서 RGB로 색상 변환\n",
    "        image_resized = cv2.resize(image, (128, 128))  # 이미지 리사이즈\n",
    "        images_resized.append(image_resized)  # 결과 리스트에 추가\n",
    "    images_resized = np.array(images_resized) / 255.0  # numpy 배열로 변환 및 정규화\n",
    "    return images_resized\n",
    "\n",
    "train_image_resized = resize_img(train_image_paths)\n",
    "valid_image_resized = resize_img(valid_image_paths)\n",
    "test_image_resized = resize_img(test_image_paths)\n",
    "\n",
    "train_label_data = np.array(train_label_data)\n",
    "valid_label_data = np.array(valid_label_data)\n",
    "test_label_data = np.array(test_label_data)\n",
    "\n",
    "print('done')\n",
    "\n",
    "print(type(valid_label_data))  # 데이터 타입 확인\n",
    "if isinstance(valid_label_data, np.ndarray):\n",
    "    print(valid_label_data.shape)  # numpy 배열인 경우, 모양 확인\n",
    "print(type(train_label_data))  # 데이터 타입 확인\n",
    "if isinstance(train_label_data, np.ndarray):\n",
    "    print(train_label_data.shape)  # numpy 배열인 경우, 모양 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b58b1e-89af-4686-a157-4df1dea76dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "247/247 [==============================] - 7s 17ms/step - loss: 0.6926 - accuracy: 0.3820 - val_loss: 0.6841 - val_accuracy: 0.2779\n",
      "Epoch 2/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.6840 - accuracy: 0.2951 - val_loss: 0.6676 - val_accuracy: 0.2839\n",
      "Epoch 3/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.6613 - accuracy: 0.3373 - val_loss: 0.6450 - val_accuracy: 0.3335\n",
      "Epoch 4/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.6396 - accuracy: 0.3655 - val_loss: 0.6257 - val_accuracy: 0.2975\n",
      "Epoch 5/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.6142 - accuracy: 0.3642 - val_loss: 0.5978 - val_accuracy: 0.3649\n",
      "Epoch 6/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.5892 - accuracy: 0.4103 - val_loss: 0.5785 - val_accuracy: 0.3708\n",
      "Epoch 7/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.5640 - accuracy: 0.4261 - val_loss: 0.5607 - val_accuracy: 0.4352\n",
      "Epoch 8/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.5403 - accuracy: 0.4503 - val_loss: 0.5458 - val_accuracy: 0.4222\n",
      "Epoch 9/25\n",
      "247/247 [==============================] - 4s 16ms/step - loss: 0.5249 - accuracy: 0.4613 - val_loss: 0.5326 - val_accuracy: 0.4228\n",
      "Epoch 10/25\n",
      "247/247 [==============================] - 4s 16ms/step - loss: 0.4955 - accuracy: 0.4771 - val_loss: 0.5132 - val_accuracy: 0.4666\n",
      "Epoch 11/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.4871 - accuracy: 0.4821 - val_loss: 0.5088 - val_accuracy: 0.4406\n",
      "Epoch 12/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.4683 - accuracy: 0.4816 - val_loss: 0.4990 - val_accuracy: 0.4772\n",
      "Epoch 13/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.4503 - accuracy: 0.5006 - val_loss: 0.4901 - val_accuracy: 0.4364\n",
      "Epoch 14/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.4356 - accuracy: 0.4948 - val_loss: 0.4780 - val_accuracy: 0.4914\n",
      "Epoch 15/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.4220 - accuracy: 0.5161 - val_loss: 0.4741 - val_accuracy: 0.4867\n",
      "Epoch 16/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.4124 - accuracy: 0.5263 - val_loss: 0.4638 - val_accuracy: 0.4790\n",
      "Epoch 17/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.3983 - accuracy: 0.5224 - val_loss: 0.4650 - val_accuracy: 0.4554\n",
      "Epoch 18/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.3852 - accuracy: 0.5189 - val_loss: 0.4548 - val_accuracy: 0.4760\n",
      "Epoch 19/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.3735 - accuracy: 0.5271 - val_loss: 0.4510 - val_accuracy: 0.4962\n",
      "Epoch 20/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.3668 - accuracy: 0.5368 - val_loss: 0.4523 - val_accuracy: 0.5115\n",
      "Epoch 21/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.3548 - accuracy: 0.5452 - val_loss: 0.4438 - val_accuracy: 0.4973\n",
      "Epoch 22/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.3511 - accuracy: 0.5328 - val_loss: 0.4543 - val_accuracy: 0.4831\n",
      "Epoch 23/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.3470 - accuracy: 0.5458 - val_loss: 0.4424 - val_accuracy: 0.4914\n",
      "Epoch 24/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.3304 - accuracy: 0.5486 - val_loss: 0.4491 - val_accuracy: 0.4897\n",
      "Epoch 25/25\n",
      "247/247 [==============================] - 4s 15ms/step - loss: 0.3265 - accuracy: 0.5612 - val_loss: 0.4374 - val_accuracy: 0.5198\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.4701 - accuracy: 0.5104\n",
      "\n",
      "테스트 정확도: 0.5103734731674194\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "# 모델 구성\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    # 멀티라벨 분류를 위한 sigmoid 활성화 함수 사용\n",
    "    Dense(3, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=7, mode='min', verbose=1)\n",
    "\n",
    "\n",
    "# 이제 모델 학습을 실행할 수 있습니다.\n",
    "model.fit(train_image_resized, \n",
    "          train_label_data, \n",
    "          validation_data=(valid_image_resized, valid_label_data), \n",
    "          epochs=25, \n",
    "          batch_size=32,\n",
    "         callbacks=[earlystopping])\n",
    "\n",
    "# 테스트 데이터셋으로 모델 평가\n",
    "test_loss, test_acc = model.evaluate(test_image_resized, test_label_data)\n",
    "print('\\n테스트 정확도:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c73b61f-0d5c-43f7-8992-6b354be84c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
