{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a07171-d825-42ed-aac8-03b0aa756d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import resnet50, ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea1e6b0b-9644-496d-a893-4554fedc63fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(r'E:\\AImodel\\models\\Face-ResNet-Plank-remove-model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbdc504a-034f-457c-a382-fb29491a6fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 727ms/step\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image_path, target_size=(128, 128)):\n",
    "    \"\"\"이미지 파일을 불러와 전처리하는 함수\"\"\"\n",
    "    img = image.load_img(image_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # 모델 예측을 위해 차원 확장\n",
    "    img_array /= 255.0  # 이미지를 0과 1 사이로 스케일링\n",
    "    return img_array\n",
    "\n",
    "def load_and_preprocess_from_directory(directory_path, target_size=(128, 128)):\n",
    "    \"\"\"지정된 디렉토리 내의 모든 이미지를 불러와 전처리하는 함수\"\"\"\n",
    "    processed_images = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img = preprocess_image(file_path, target_size=target_size)\n",
    "            processed_images.append(img)\n",
    "    return np.vstack(processed_images)  # 전처리된 이미지들을 하나의 numpy 배열로 합침\n",
    "\n",
    "dir = r'E:\\AItemp\\testdata\\plank test'\n",
    "preprocessed_images = load_and_preprocess_from_directory(dir)\n",
    "predictions = model.predict(preprocessed_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "324468ba-96b1-4485-b6dc-e750304e4602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델은 총 4개의 클래스를 가지고 있습니다.\n",
      "Image 1:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 2:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 3:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 4:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 5:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 6:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 7:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 8:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 9:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 10:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 11:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 12:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 13:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 14:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 15:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 16:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 17:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 18:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 19:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 20:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 21:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 22:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 23:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n",
      "Image 24:\n",
      "  class1: 0.00%\n",
      "  class2: 1.00%\n",
      "  class3: 0.00%\n",
      "  class4: 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델의 출력층에 접근하여 클래스의 개수 얻기\n",
    "output_layer = model.layers[-1]  # 모델의 마지막 층 (출력층)을 가져옴\n",
    "num_classes = output_layer.units  # 출력층의 유닛 수를 가져옴, 이는 클래스의 수와 동일\n",
    "\n",
    "print(f'모델은 총 {num_classes}개의 클래스를 가지고 있습니다.')\n",
    "class_labels = []\n",
    "# 클래스 라벨 정의 (예: num_classes 개의 클래스)\n",
    "for i in range(num_classes):\n",
    "    class_labels.append(f'class{i+1}')\n",
    "\n",
    "# 예를 들어, num_classes가 3이라면 class_labels는 ['class1', 'class2', 'class3']이 됩니다.\n",
    "\n",
    "\n",
    "# predictions 배열에서 각 입력에 대한 모든 클래스의 확률 출력\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f'Image {i+1}:')\n",
    "    for j, class_label in enumerate(class_labels):\n",
    "        print(f'  {class_label}: {prediction[j]:.2f}%')\n",
    "    print()  # 각 이미지의 예측 결과 사이에 공백 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae52158-e6c0-4e32-9355-640517aa6f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class1: 0개의 이미지가 이 클래스가 가장 높은 확률을 가집니다.\n",
      "class2: 24개의 이미지가 이 클래스가 가장 높은 확률을 가집니다.\n",
      "class3: 0개의 이미지가 이 클래스가 가장 높은 확률을 가집니다.\n",
      "class4: 0개의 이미지가 이 클래스가 가장 높은 확률을 가집니다.\n"
     ]
    }
   ],
   "source": [
    "# 예측 배열에서 각 입력에 대해 최고 확률을 가진 클래스의 인덱스를 찾음\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 각 클래스별 이미지 수를 계산하기 위한 딕셔너리 초기화\n",
    "class_counts = {class_label: 0 for class_label in class_labels}\n",
    "\n",
    "# 예측된 클래스별로 이미지 수를 계산\n",
    "for class_index in predicted_classes:\n",
    "    class_label = class_labels[class_index]\n",
    "    class_counts[class_label] += 1\n",
    "\n",
    "# 결과 출력\n",
    "for class_label, count in class_counts.items():\n",
    "    print(f'{class_label}: {count}개의 이미지가 이 클래스가 가장 높은 확률을 가집니다.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f333ff-375e-4cae-8130-b3aea46944cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # Grad-CAM 알고리즘 구현\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # 이 클래스에 대한 최종 컨볼루션 레이어의 그래디언트\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # 가중치 평균값\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # 최종 컨볼루션 레이어의 출력에 가중치를 곱함\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # ReLU 활성화 및 정규화\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c41ff7a8-8693-45ca-9034-86b51ecd4a9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'E:\\\\AItemp\\\\test\\\\plank test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 폴더 내의 모든 jpg 파일에 대해 처리\u001b[39;00m\n\u001b[0;32m      5\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAItemp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mplank test\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 대상 폴더 경로\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m image_files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_folder, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_files:\n\u001b[0;32m      9\u001b[0m     img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mload_img(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'E:\\\\AItemp\\\\test\\\\plank test'"
     ]
    }
   ],
   "source": [
    "# 사전 학습된 신경망 모델을 불러오고 구조 확인\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# 폴더 내의 모든 jpg 파일에 대해 처리\n",
    "image_folder = r'E:\\AItemp\\test\\plank test'  # 대상 폴더 경로\n",
    "image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
    "\n",
    "for image_path in image_files:\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    \n",
    "    # 영상을 신경망 형태로 변환\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = resnet50.preprocess_input(x)\n",
    "\n",
    "    last_conv_layer = model.get_layer(\"conv5_block3_out\")\n",
    "    model_1 = keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    input_2 = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x_2 = model.get_layer(\"avg_pool\")(input_2)\n",
    "    x_2 = model.get_layer(\"predictions\")(x_2)\n",
    "    model_2 = keras.Model(input_2, x_2)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        output_1 = model_1(x)\n",
    "        tape.watch(output_1)\n",
    "        preds = model_2(output_1)\n",
    "        class_id = tf.argmax(preds[0])\n",
    "        output_2 = preds[:, class_id]\n",
    "\n",
    "    grads = tape.gradient(output_2, output_1)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    output_1 = output_1.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        output_1[:, :, i] *= pooled_grads[i]\n",
    "    heatmap = np.mean(output_1, axis=-1)\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    \n",
    "    # 열지도를 입력 영상에 씌움\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "    color = jet(np.arange(256))[:, :3]\n",
    "    color_heatmap = color[heatmap]\n",
    "\n",
    "    color_heatmap = keras.preprocessing.image.array_to_img(color_heatmap)\n",
    "    color_heatmap = color_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    color_heatmap = keras.preprocessing.image.img_to_array(color_heatmap)\n",
    "\n",
    "    overlay_img = color_heatmap * 0.4 + img\n",
    "    overlay_img = keras.preprocessing.image.array_to_img(overlay_img)\n",
    "\n",
    "    # 결과 이미지 디스플레이\n",
    "    plt.figure()\n",
    "    plt.imshow(overlay_img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f728ace-7f97-431d-becf-5adda5fcb9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.applications import resnet50, ResNet50\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    " \n",
    "# #사전 학습된 신경망 모델을 불러오고 구조 확인\n",
    "# model = ResNet50(weights='imagenet')\n",
    "# #model.summary()\n",
    " \n",
    "# #지정된 영상을 불러와 크기 조정하고 화면에 디스플레이\n",
    "# image_path = r'E:\\AItemp\\test\\plank test'#r'E:\\AItemp\\BicycleCrunch\\training\\BicycleCrunch_505\\505-Z1_C-0000016.jpg'\n",
    "# img = image.load_img(image_path, target_size = (224,224))\n",
    "# plt.matshow(img)\n",
    " \n",
    "# #영상을 신경망 형태로 변환\n",
    "# x=image.img_to_array(img)\n",
    "# x=np.expand_dims(x,axis=0)\n",
    "# x=resnet50.preprocess_input(x)\n",
    " \n",
    "# #신경망 모델의 특 징 추출 부분에서 마지막 층을 지정\n",
    "# #특징 추출 부분만으로 구성된 model_1만들기\n",
    "# last_conv_layer = model.get_layer(\"conv5_block3_out\")\n",
    " \n",
    "# model_1= keras.Model(model.inputs, last_conv_layer.output)\n",
    " \n",
    "# #분류 (전역평균풀링 또는 완전연결층) 부분만으로 구성된 model__2만들기\n",
    "# input_2 = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "# x_2 = model.get_layer(\"avg_pool\")(input_2)\n",
    "# x_2 = model.get_layer(\"predictions\")(x_2)\n",
    "# model_2=keras.Model(input_2,x_2)\n",
    " \n",
    "# #GradientTape함수를 이용한 그레디언트 계산\n",
    "# with tf.GradientTape() as tape:\n",
    "#     output_1 = model_1(x)\n",
    "#     tape.watch(output_1) #마지막 층으로 미분하기 위한 준비\n",
    "#     preds = model_2(output_1)\n",
    "#     class_id = tf.argmax(preds[0])\n",
    "#     output_2 = preds[:,class_id]\n",
    " \n",
    "# grads = tape.gradient(output_2, output_1) #그레디언트 계산\n",
    "# pooled_grads = tf.reduce_mean(grads,axis=(0,1,2)) #식5 적용\n",
    " \n",
    "# output_1 = output_1.numpy()[0]\n",
    "# pooled_grads = pooled_grads.numpy()\n",
    "# for i in range(pooled_grads.shape[-1]):\n",
    "#     output_1[:,:,i]*=pooled_grads[i]\n",
    "# heatmap=np.mean(output_1, axis=-1)\n",
    " \n",
    "# heatmap =np.maximum(heatmap, 0)/np.max(heatmap) #정규화\n",
    "# plt.matshow(heatmap)\n",
    " \n",
    "# #열지도를 입력 영상에 씌움\n",
    "# img =image.load_img(image_path) #입력 영상을 다시 받음\n",
    " \n",
    "# img=image.img_to_array(img)\n",
    "# heatmap=np.uint8(255*heatmap) # [0,255]로 변환\n",
    " \n",
    "# jet = cm.get_cmap(\"jet\") #jet 컬러맵으로 표시\n",
    "# color = jet(np.arange(256))[:,:3]\n",
    "# color_heatmap = color[heatmap]\n",
    " \n",
    "# color_heatmap = keras.preprocessing.image.array_to_img(color_heatmap)\n",
    "# color_heatmap = color_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "# color_heatmap = keras.preprocessing.image.img_to_array(color_heatmap)\n",
    " \n",
    "# overlay_img= color_heatmap*0.4+img #덧씌움\n",
    "# overlay_img = keras.preprocessing.image.array_to_img(overlay_img)\n",
    "# plt.matshow(overlay_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468207e4-751e-4602-806a-dc83d02b18fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
