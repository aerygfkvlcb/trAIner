{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037f84ae-9b6b-4fd8-aa54-ebe006186b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36640 images belonging to 32 classes.\n",
      "Found 7870 images belonging to 32 classes.\n",
      "Found 7854 images belonging to 32 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "train_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\StandingSideCrunch\\training'\n",
    "val_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\StandingSideCrunch\\validation'\n",
    "test_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\StandingSideCrunch\\test'\n",
    "\n",
    "# ImageDataGenerator 초기화\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # 이미지를 0과 1 사이의 값으로 정규화\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터셋을 위한 제너레이터 생성\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f359c00e-9c0d-4ae8-ab24-d8125804111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        if layer.name == 'block5_conv1' or layer.name == 'block5_conv2':\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False    \n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.Flatten())\n",
    "    # Dense 레이어의 유닛 수를 하이퍼파라미터로 사용\n",
    "    model.add(layers.Dense(units=hp.Int('units', min_value=64, max_value=512, step=64), activation = 'relu'))\n",
    "    model.add(layers.Dense(32, activation = 'softmax'))\n",
    "\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-3, sampling=\"log\")\n",
    "    model.compile(keras.optimizers.Adam(learning_rate=lr), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268edabb-2d5b-4485-bb78-b64236c5bcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 64, 'sampling': 'linear'}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # 시도할 하이퍼파라미터 조합의 최대 개수\n",
    "    executions_per_trial=1,  # 각 하이퍼파라미터 설정을 평가하기 위해 모델을 훈련시킬 횟수\n",
    "    directory=r'E:\\AInotes\\자세교정\\모델학습\\VGG\\random_search',  # 튜닝 세션의 결과를 저장할 디렉토리 이름\n",
    "    project_name='VGG_SSC_RS_01'  # 프로젝트 이름\n",
    ")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d2d3cf-10ce-4dcd-acba-f8c8ab2a1218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 09m 54s]\n",
      "val_accuracy: 0.7181122303009033\n",
      "\n",
      "Best val_accuracy So Far: 0.7420918345451355\n",
      "Total elapsed time: 00h 47m 02s\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.01, verbose=1)\n",
    "\n",
    "tuner.search(train_generator,\n",
    "             steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "             validation_data=validation_generator, \n",
    "             validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "             epochs=40,\n",
    "             callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터로 모델 빌드\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "#best_models = tuner.get_best_models(1)\n",
    "#final_model = best_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad7ab4dc-1326-4f86-9113-ee157bab2980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal value for units is 256\n",
      "The optimal value for lr is 0.0002003863307442027\n",
      "Epoch 1/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 2.5341 - accuracy: 0.1983 - val_loss: 2.1765 - val_accuracy: 0.2907\n",
      "Epoch 2/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 1.8913 - accuracy: 0.3713 - val_loss: 1.7021 - val_accuracy: 0.4314\n",
      "Epoch 3/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 1.5285 - accuracy: 0.4862 - val_loss: 1.5389 - val_accuracy: 0.4860\n",
      "Epoch 4/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 1.2416 - accuracy: 0.5745 - val_loss: 1.3345 - val_accuracy: 0.5536\n",
      "Epoch 5/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 1.0213 - accuracy: 0.6497 - val_loss: 1.2085 - val_accuracy: 0.5918\n",
      "Epoch 6/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.8497 - accuracy: 0.7042 - val_loss: 1.1070 - val_accuracy: 0.6190\n",
      "Epoch 7/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.7101 - accuracy: 0.7542 - val_loss: 1.0586 - val_accuracy: 0.6490\n",
      "Epoch 8/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.6027 - accuracy: 0.7894 - val_loss: 0.9851 - val_accuracy: 0.6719\n",
      "Epoch 9/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.5167 - accuracy: 0.8166 - val_loss: 0.9645 - val_accuracy: 0.6865\n",
      "Epoch 10/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.4481 - accuracy: 0.8419 - val_loss: 0.9634 - val_accuracy: 0.6945\n",
      "Epoch 11/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.3847 - accuracy: 0.8624 - val_loss: 0.9560 - val_accuracy: 0.7111\n",
      "Epoch 12/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.3346 - accuracy: 0.8815 - val_loss: 0.9353 - val_accuracy: 0.7102\n",
      "Epoch 13/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.2992 - accuracy: 0.8945 - val_loss: 0.9825 - val_accuracy: 0.7139\n",
      "Epoch 14/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.2635 - accuracy: 0.9055 - val_loss: 1.0007 - val_accuracy: 0.7269\n",
      "Epoch 15/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.2380 - accuracy: 0.9160 - val_loss: 1.0414 - val_accuracy: 0.7135\n",
      "Epoch 16/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.2084 - accuracy: 0.9258 - val_loss: 0.9917 - val_accuracy: 0.7365\n",
      "Epoch 17/40\n",
      "1145/1145 [==============================] - 40s 35ms/step - loss: 0.1991 - accuracy: 0.9308 - val_loss: 1.0410 - val_accuracy: 0.7297\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 모든 최적 하이퍼파라미터 출력\n",
    "for hp in best_hps.values:\n",
    "    print(f\"The optimal value for {hp} is {best_hps.get(hp)}\")\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "                    epochs=40,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# 모델 평가 (테스트 데이터셋)\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print('\\n테스트 정확도:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c63c1-38bc-4bed-bc0c-e25d97e5f879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
