{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037f84ae-9b6b-4fd8-aa54-ebe006186b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15894 images belonging to 16 classes.\n",
      "Found 3415 images belonging to 16 classes.\n",
      "Found 3406 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "train_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\LyingLegRaise\\training'\n",
    "val_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\LyingLegRaise\\validation'\n",
    "test_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\LyingLegRaise\\test'\n",
    "\n",
    "# ImageDataGenerator 초기화\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # 이미지를 0과 1 사이의 값으로 정규화\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터셋을 위한 제너레이터 생성\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f359c00e-9c0d-4ae8-ab24-d8125804111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        if layer.name == 'block5_conv1' or layer.name == 'block5_conv2':\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False    \n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.Flatten())\n",
    "    # Dense 레이어의 유닛 수를 하이퍼파라미터로 사용\n",
    "    model.add(layers.Dense(units=hp.Int('units', min_value=128, max_value=512, step=128), activation = 'relu'))\n",
    "    model.add(layers.Dense(16, activation = 'softmax'))\n",
    "\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-3, sampling=\"log\")\n",
    "    model.compile(keras.optimizers.Adam(learning_rate=lr), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268edabb-2d5b-4485-bb78-b64236c5bcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 128, 'sampling': 'linear'}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # 시도할 하이퍼파라미터 조합의 최대 개수\n",
    "    executions_per_trial=1,  # 각 하이퍼파라미터 설정을 평가하기 위해 모델을 훈련시킬 횟수\n",
    "    directory=r'E:\\AInotes\\자세교정\\모델학습\\VGG\\random_search',  # 튜닝 세션의 결과를 저장할 디렉토리 이름\n",
    "    project_name='VGG_LyingLegRaise_RS_01'  # 프로젝트 이름\n",
    ")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d2d3cf-10ce-4dcd-acba-f8c8ab2a1218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 05m 12s]\n",
      "val_accuracy: 0.7438089847564697\n",
      "\n",
      "Best val_accuracy So Far: 0.7488207817077637\n",
      "Total elapsed time: 00h 22m 06s\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.01, verbose=1)\n",
    "\n",
    "tuner.search(train_generator,\n",
    "             steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "             validation_data=validation_generator, \n",
    "             validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "             epochs=25,\n",
    "             callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터로 모델 빌드\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "#best_models = tuner.get_best_models(1)\n",
    "#final_model = best_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad7ab4dc-1326-4f86-9113-ee157bab2980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal value for units is 128\n",
      "The optimal value for lr is 0.00011096241428976375\n",
      "Epoch 1/40\n",
      "496/496 [==============================] - 18s 36ms/step - loss: 2.2258 - accuracy: 0.2092 - val_loss: 2.0603 - val_accuracy: 0.2633\n",
      "Epoch 2/40\n",
      "496/496 [==============================] - 18s 36ms/step - loss: 1.8619 - accuracy: 0.3183 - val_loss: 1.7867 - val_accuracy: 0.3449\n",
      "Epoch 3/40\n",
      "496/496 [==============================] - 18s 36ms/step - loss: 1.5796 - accuracy: 0.4212 - val_loss: 1.5672 - val_accuracy: 0.4354\n",
      "Epoch 4/40\n",
      "496/496 [==============================] - 18s 36ms/step - loss: 1.3145 - accuracy: 0.5243 - val_loss: 1.4471 - val_accuracy: 0.4814\n",
      "Epoch 5/40\n",
      "496/496 [==============================] - 18s 36ms/step - loss: 1.1099 - accuracy: 0.5970 - val_loss: 1.2750 - val_accuracy: 0.5327\n",
      "Epoch 6/40\n",
      "496/496 [==============================] - 19s 38ms/step - loss: 0.9307 - accuracy: 0.6620 - val_loss: 1.1513 - val_accuracy: 0.5902\n",
      "Epoch 7/40\n",
      "496/496 [==============================] - 18s 37ms/step - loss: 0.7615 - accuracy: 0.7276 - val_loss: 1.1062 - val_accuracy: 0.6055\n",
      "Epoch 8/40\n",
      "496/496 [==============================] - 18s 36ms/step - loss: 0.6452 - accuracy: 0.7708 - val_loss: 1.0142 - val_accuracy: 0.6480\n",
      "Epoch 9/40\n",
      "496/496 [==============================] - 18s 36ms/step - loss: 0.5486 - accuracy: 0.8053 - val_loss: 0.9542 - val_accuracy: 0.6636\n",
      "Epoch 10/40\n",
      "496/496 [==============================] - 17s 35ms/step - loss: 0.4530 - accuracy: 0.8399 - val_loss: 0.9235 - val_accuracy: 0.6966\n",
      "Epoch 11/40\n",
      "496/496 [==============================] - 17s 35ms/step - loss: 0.3837 - accuracy: 0.8647 - val_loss: 0.9069 - val_accuracy: 0.7108\n",
      "Epoch 12/40\n",
      "496/496 [==============================] - 17s 34ms/step - loss: 0.3250 - accuracy: 0.8865 - val_loss: 0.8783 - val_accuracy: 0.7102\n",
      "Epoch 13/40\n",
      "496/496 [==============================] - 17s 34ms/step - loss: 0.2904 - accuracy: 0.9015 - val_loss: 0.8907 - val_accuracy: 0.7173\n",
      "Epoch 14/40\n",
      "496/496 [==============================] - 17s 34ms/step - loss: 0.2340 - accuracy: 0.9204 - val_loss: 0.9082 - val_accuracy: 0.7255\n",
      "Epoch 15/40\n",
      "496/496 [==============================] - 17s 35ms/step - loss: 0.2031 - accuracy: 0.9325 - val_loss: 0.9604 - val_accuracy: 0.7146\n",
      "Epoch 16/40\n",
      "496/496 [==============================] - 17s 35ms/step - loss: 0.2063 - accuracy: 0.9282 - val_loss: 0.9315 - val_accuracy: 0.7185\n",
      "Epoch 17/40\n",
      "496/496 [==============================] - 17s 35ms/step - loss: 0.1535 - accuracy: 0.9491 - val_loss: 0.8878 - val_accuracy: 0.7308\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 모든 최적 하이퍼파라미터 출력\n",
    "for hp in best_hps.values:\n",
    "    print(f\"The optimal value for {hp} is {best_hps.get(hp)}\")\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "                    epochs=40,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# 모델 평가 (테스트 데이터셋)\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print('\\n테스트 정확도:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c63c1-38bc-4bed-bc0c-e25d97e5f879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
