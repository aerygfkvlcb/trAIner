{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a662bf-423e-49be-90dd-9d09bba9d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36640 images belonging to 32 classes.\n",
      "Found 7870 images belonging to 32 classes.\n",
      "Found 7854 images belonging to 32 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import EfficientNetB4 \n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "# 데이터셋 경로 설정\n",
    "train_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\StandingSideCrunch\\training'\n",
    "val_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\StandingSideCrunch\\validation'\n",
    "test_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\StandingSideCrunch\\test'\n",
    "\n",
    "# ImageDataGenerator 초기화\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터셋을 위한 제너레이터 생성\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e30988-ebab-4f60-ac70-2ee1563d6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in base_model.layers[-20:]:\n",
    "        layer.trainable = True   \n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    # Dense 레이어의 유닛 수를 하이퍼파라미터로 사용\n",
    "    model.add(layers.Dense(units=hp.Int('units', min_value=128, max_value=512, step=128), activation = 'relu'))\n",
    "    model.add(layers.Dense(32, activation = 'softmax'))\n",
    "\n",
    "    # learning_rate를 하이퍼파라미터로 사용\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-3, sampling='LOG')),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df9ac25-5a23-45fd-a2a2-60e1db6de404",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 시도할 하이퍼파라미터 조합의 최대 개수\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutions_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 각 하이퍼파라미터 설정을 평가하기 위해 모델을 훈련시킬 횟수\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mAInotes\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m자세교정\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m모델학습\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mEffiNet\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mrandom_search\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 튜닝 세션의 결과를 저장할 디렉토리 이름\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEN_SSC_RS_01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 프로젝트 이름\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch_space_summary()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_tuner\\src\\tuners\\randomsearch.py:174\u001b[0m, in \u001b[0;36mRandomSearch.__init__\u001b[1;34m(self, hypermodel, objective, max_trials, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m=\u001b[39m seed\n\u001b[0;32m    164\u001b[0m oracle \u001b[38;5;241m=\u001b[39m RandomSearchOracle(\n\u001b[0;32m    165\u001b[0m     objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[0;32m    166\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39mmax_trials,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m     max_consecutive_failed_trials\u001b[38;5;241m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[0;32m    173\u001b[0m )\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(oracle, hypermodel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:122\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[1;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner\u001b[38;5;241m.\u001b[39mrun_trial:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`hypermodel` if the user defines the search space in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing a `HyperModel` instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m     )\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    123\u001b[0m     oracle\u001b[38;5;241m=\u001b[39moracle,\n\u001b[0;32m    124\u001b[0m     hypermodel\u001b[38;5;241m=\u001b[39mhypermodel,\n\u001b[0;32m    125\u001b[0m     directory\u001b[38;5;241m=\u001b[39mdirectory,\n\u001b[0;32m    126\u001b[0m     project_name\u001b[38;5;241m=\u001b[39mproject_name,\n\u001b[0;32m    127\u001b[0m     logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[0;32m    128\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39moverwrite,\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    130\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_model_size \u001b[38;5;241m=\u001b[39m max_model_size\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m optimizer\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:132\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[1;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreload()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_populate_initial_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Run in distributed mode.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist_utils\u001b[38;5;241m.\u001b[39mhas_chief_oracle() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dist_utils\u001b[38;5;241m.\u001b[39mis_chief_oracle():\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# Proxies requests to the chief oracle.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# Avoid import at the top, to avoid inconsistent protobuf versions.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:192\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mdeclare_hyperparameters(hp)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_space(hp)\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_activate_all_conditions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:149\u001b[0m, in \u001b[0;36mBaseTuner._activate_all_conditions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    147\u001b[0m hp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_space()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_space(hp)\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# Update the recorded scopes.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# learning_rate를 하이퍼파라미터로 사용\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[43moptimizers\u001b[49m\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mhp\u001b[38;5;241m.\u001b[39mFloat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, min_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, max_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, sampling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOG\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     20\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizers' is not defined"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # 시도할 하이퍼파라미터 조합의 최대 개수\n",
    "    executions_per_trial=1,  # 각 하이퍼파라미터 설정을 평가하기 위해 모델을 훈련시킬 횟수\n",
    "    directory=r'E:\\AInotes\\자세교정\\모델학습\\EffiNet\\random_search',  # 튜닝 세션의 결과를 저장할 디렉토리 이름\n",
    "    project_name='EN_SSC_RS_01'  # 프로젝트 이름\n",
    ")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b7db6-0780-4074-ba61-8a15480d5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, min_delta=0, verbose=1)\n",
    "\n",
    "tuner.search(train_generator,\n",
    "             steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "             validation_data=validation_generator, \n",
    "             validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "             epochs=25,\n",
    "             callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# 최적의 하이퍼파라미터로 모델 빌드\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "#best_models = tuner.get_best_models(1)\n",
    "#final_model = best_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfa9c3-8c93-4d54-8868-326d7a3d76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 최적 하이퍼파라미터 출력\n",
    "for hp in best_hps.values:\n",
    "    print(f\"The optimal value for {hp} is {best_hps.get(hp)}\")\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "                    epochs=25,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# 모델 평가 (테스트 데이터셋)\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print('\\n테스트 정확도:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a626528-7dd0-425a-91e8-cee2e89409c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
