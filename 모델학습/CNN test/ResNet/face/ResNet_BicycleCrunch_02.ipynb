{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037f84ae-9b6b-4fd8-aa54-ebe006186b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7775 images belonging to 8 classes.\n",
      "Found 1670 images belonging to 8 classes.\n",
      "Found 1667 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "train_dir = r'E:\\AI\\dataset_skeleton_sep\\side\\BicycleCrunch\\training'\n",
    "val_dir = r'E:\\AI\\dataset_skeleton_sep\\side\\BicycleCrunch\\validation'\n",
    "test_dir = r'E:\\AI\\dataset_skeleton_sep\\side\\BicycleCrunch\\test'\n",
    "\n",
    "# ImageDataGenerator 초기화\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # 이미지를 0과 1 사이의 값으로 정규화\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터셋을 위한 제너레이터 생성\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973f0e2-cc5d-49b6-a8cf-257f84ad5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Input, MaxPooling2D, BatchNormalization, Activation, Dense, \\\n",
    "GlobalAveragePooling2D,ZeroPadding2D, Add\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "def resnetConv2D(x, filters=64, strides = (1,1), filters_scale = 1) :\n",
    "    filters = filters*filters_scale\n",
    "\n",
    "    x = Conv2D(filters,(1,1),strides=strides,padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(4*filters, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnetConv1(x) :\n",
    "    x = ZeroPadding2D(padding=(3,3))(x)\n",
    "    x = Conv2D(64,(7,7),strides=(2,2),padding = 'valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnetConv2(x) :\n",
    "    x = MaxPooling2D((3,3), 2)(x)\n",
    "\n",
    "    sc = x ## shortcut\n",
    "\n",
    "    for i in range(0,3) :\n",
    "        if i == 0 :\n",
    "            x = resnetConv2D(x, strides = (1,1),filters_scale = 1)\n",
    "            \n",
    "            sc = Conv2D(256, kernel_size = (1, 1), strides=(1, 1), padding='valid')(sc)            \n",
    "            x = BatchNormalization()(x)\n",
    "            sc = BatchNormalization()(sc)\n",
    "            \n",
    "            x = Add()([x, sc])\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "            sc = x\n",
    "\n",
    "        else : \n",
    "            x = resnetConv2D(x,strides = (1,1), filters_scale = 1)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            x = Add()([x, sc])\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "            sc = x\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnetConv3(x) :\n",
    "    sc = x\n",
    "\n",
    "    for i in range(0,4) : \n",
    "        if i == 0 :\n",
    "            x = resnetConv2D(x,strides=(2,2),filters_scale=2)\n",
    "            sc = Conv2D(512,kernel_size =(1,1),strides=(2,2),padding='valid')(sc)\n",
    "            x=BatchNormalization()(x)\n",
    "            sc = BatchNormalization()(sc)\n",
    "            x = Add()([x,sc])\n",
    "            x = Activation('relu')(x)\n",
    "            sc = x\n",
    "        \n",
    "        else :\n",
    "            x = resnetConv2D(x,strides = (1,1), filters_scale=2)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            x = Add()([x,sc])\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "            sc = x\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnetConv4(x) :\n",
    "    sc = x\n",
    "\n",
    "    for i in range(0, 6) :\n",
    "        if i == 0 :\n",
    "            x = resnetConv2D(x, strides = (2,2), filters_scale = 4)\n",
    "\n",
    "            sc = Conv2D(filters = 1024, kernel_size = (1,1), strides = (2,2), padding = 'valid')(sc)\n",
    "            x = BatchNormalization()(x)\n",
    "            sc = BatchNormalization()(sc)\n",
    "            x = Add()([x, sc])\n",
    "            Activation('relu')(x)\n",
    "            sc = x\n",
    "\n",
    "\n",
    "        else :\n",
    "            x = resnetConv2D(x, strides = (1,1), filters_scale=4)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            x = Add()([x,sc])\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "            sc = x\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnetConv5(x) :\n",
    "    sc = x\n",
    "\n",
    "    for i in range(0, 3) :\n",
    "        if i == 0 :\n",
    "            x = resnetConv2D(x,strides = (2,2),filters_scale = 8)\n",
    "\n",
    "            sc = Conv2D(filters = 2048, kernel_size = (1,1), strides = (2,2),padding = 'valid')(sc)\n",
    "            x = BatchNormalization()(x)\n",
    "            sc = BatchNormalization()(sc)\n",
    "\n",
    "            x = Add()([x,sc])\n",
    "            x = Activation('relu')(x)\n",
    "            sc = x\n",
    "        else :\n",
    "            x = resnetConv2D(x, strides = (1,1),filters_scale = 8)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "            x = Add()([x, sc])\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "            sc = x\n",
    "\n",
    "    return x\n",
    "\n",
    "def myModel() :\n",
    "    _input = Input(shape = (128,128,3), dtype = 'float32', name='input')\n",
    "    x = resnetConv1(_input)\n",
    "    x = resnetConv2(x)\n",
    "    x = resnetConv3(x)\n",
    "    x = resnetConv4(x)\n",
    "    x = resnetConv5(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    feature_vector = Dense(256, activation = 'relu',name = 'feature_vector')(x) ## feature vector\n",
    "\n",
    "    output = Dense(8, activation='relu')(feature_vector)## age\n",
    "\n",
    "    my_resnet_model = Model(_input,output)\n",
    "\n",
    "    return my_resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43c18dc-2a64-4c4f-95a8-d2ded0404978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 134, 134, 3)  0          ['input[0][0]']                  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 64, 64, 64)   9472        ['zero_padding2d_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 64, 64, 64)  256         ['conv2d_106[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, 66, 66, 64)  0           ['activation_98[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['zero_padding2d_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 32, 32, 64)   4160        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 32, 32, 64)  256         ['conv2d_107[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 32, 32, 64)   36928       ['activation_99[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, 32, 32, 64)  256         ['conv2d_108[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 32, 32, 256)  16640       ['activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 32, 32, 256)  16640       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, 32, 32, 256)  1024       ['conv2d_109[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, 32, 32, 256)  1024       ['conv2d_110[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 32, 32, 256)  0           ['batch_normalization_109[0][0]',\n",
      "                                                                  'batch_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 32, 32, 256)  0           ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 32, 32, 64)   16448       ['activation_101[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, 32, 32, 64)  256         ['conv2d_111[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 32, 32, 64)   36928       ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, 32, 32, 64)  256         ['conv2d_112[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 32, 32, 256)  16640       ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, 32, 32, 256)  1024       ['conv2d_113[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 32, 32, 256)  0           ['batch_normalization_113[0][0]',\n",
      "                                                                  'activation_101[0][0]']         \n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 32, 32, 256)  0           ['add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 32, 32, 64)   16448       ['activation_104[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, 32, 32, 64)  256         ['conv2d_114[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 32, 32, 64)   36928       ['activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, 32, 32, 64)  256         ['conv2d_115[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 32, 32, 256)  16640       ['activation_106[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, 32, 32, 256)  1024       ['conv2d_116[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 32, 32, 256)  0           ['batch_normalization_116[0][0]',\n",
      "                                                                  'activation_104[0][0]']         \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 32, 32, 256)  0           ['add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 16, 16, 128)  32896       ['activation_107[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, 16, 16, 128)  512        ['conv2d_117[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_108 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 16, 16, 128)  147584      ['activation_108[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, 16, 16, 128)  512        ['conv2d_118[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_109 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 16, 16, 512)  66048       ['activation_109[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 16, 16, 512)  131584      ['activation_107[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, 16, 16, 512)  2048       ['conv2d_119[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 16, 16, 512)  2048       ['conv2d_120[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 16, 16, 512)  0           ['batch_normalization_119[0][0]',\n",
      "                                                                  'batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " activation_110 (Activation)    (None, 16, 16, 512)  0           ['add_35[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 16, 16, 128)  65664       ['activation_110[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 16, 16, 128)  512        ['conv2d_121[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_111 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 16, 16, 128)  147584      ['activation_111[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 16, 16, 128)  512        ['conv2d_122[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_112 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 16, 16, 512)  66048       ['activation_112[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 16, 16, 512)  2048       ['conv2d_123[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 16, 16, 512)  0           ['batch_normalization_123[0][0]',\n",
      "                                                                  'activation_110[0][0]']         \n",
      "                                                                                                  \n",
      " activation_113 (Activation)    (None, 16, 16, 512)  0           ['add_36[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 16, 16, 128)  65664       ['activation_113[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 16, 16, 128)  512        ['conv2d_124[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_114 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 16, 16, 128)  147584      ['activation_114[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 16, 16, 128)  512        ['conv2d_125[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_115 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 16, 16, 512)  66048       ['activation_115[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 16, 16, 512)  2048       ['conv2d_126[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 16, 16, 512)  0           ['batch_normalization_126[0][0]',\n",
      "                                                                  'activation_113[0][0]']         \n",
      "                                                                                                  \n",
      " activation_116 (Activation)    (None, 16, 16, 512)  0           ['add_37[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 16, 16, 128)  65664       ['activation_116[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 16, 16, 128)  512        ['conv2d_127[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_117 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 16, 16, 128)  147584      ['activation_117[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 16, 16, 128)  512        ['conv2d_128[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_118 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 16, 16, 512)  66048       ['activation_118[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 16, 16, 512)  2048       ['conv2d_129[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 16, 16, 512)  0           ['batch_normalization_129[0][0]',\n",
      "                                                                  'activation_116[0][0]']         \n",
      "                                                                                                  \n",
      " activation_119 (Activation)    (None, 16, 16, 512)  0           ['add_38[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 8, 8, 256)    131328      ['activation_119[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 8, 8, 256)   1024        ['conv2d_130[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_120 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 8, 8, 256)    590080      ['activation_120[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 8, 8, 256)   1024        ['conv2d_131[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_121 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 8, 8, 1024)   263168      ['activation_121[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 8, 8, 1024)   525312      ['activation_119[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 8, 8, 1024)  4096        ['conv2d_132[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 8, 8, 1024)  4096        ['conv2d_133[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 8, 8, 1024)   0           ['batch_normalization_132[0][0]',\n",
      "                                                                  'batch_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 8, 8, 256)    262400      ['add_39[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 8, 8, 256)   1024        ['conv2d_134[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_123 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 8, 8, 256)    590080      ['activation_123[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 8, 8, 256)   1024        ['conv2d_135[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_124 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, 8, 8, 1024)   263168      ['activation_124[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 8, 8, 1024)  4096        ['conv2d_136[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 8, 8, 1024)   0           ['batch_normalization_136[0][0]',\n",
      "                                                                  'add_39[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_125 (Activation)    (None, 8, 8, 1024)   0           ['add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 8, 8, 256)    262400      ['activation_125[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 8, 8, 256)   1024        ['conv2d_137[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_126 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 8, 8, 256)    590080      ['activation_126[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 8, 8, 256)   1024        ['conv2d_138[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_127 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 8, 8, 1024)   263168      ['activation_127[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, 8, 8, 1024)  4096        ['conv2d_139[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 8, 8, 1024)   0           ['batch_normalization_139[0][0]',\n",
      "                                                                  'activation_125[0][0]']         \n",
      "                                                                                                  \n",
      " activation_128 (Activation)    (None, 8, 8, 1024)   0           ['add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 8, 8, 256)    262400      ['activation_128[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 8, 8, 256)   1024        ['conv2d_140[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_129 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 8, 8, 256)    590080      ['activation_129[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 8, 8, 256)   1024        ['conv2d_141[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_130 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 8, 8, 1024)   263168      ['activation_130[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, 8, 8, 1024)  4096        ['conv2d_142[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 8, 8, 1024)   0           ['batch_normalization_142[0][0]',\n",
      "                                                                  'activation_128[0][0]']         \n",
      "                                                                                                  \n",
      " activation_131 (Activation)    (None, 8, 8, 1024)   0           ['add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 8, 8, 256)    262400      ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, 8, 8, 256)   1024        ['conv2d_143[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_132 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 8, 8, 256)    590080      ['activation_132[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_144 (Batch  (None, 8, 8, 256)   1024        ['conv2d_144[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_133 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 8, 8, 1024)   263168      ['activation_133[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_145 (Batch  (None, 8, 8, 1024)  4096        ['conv2d_145[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 8, 8, 1024)   0           ['batch_normalization_145[0][0]',\n",
      "                                                                  'activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " activation_134 (Activation)    (None, 8, 8, 1024)   0           ['add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 8, 8, 256)    262400      ['activation_134[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 8, 8, 256)   1024        ['conv2d_146[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_135 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 8, 8, 256)    590080      ['activation_135[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 8, 8, 256)   1024        ['conv2d_147[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_136 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 8, 8, 1024)   263168      ['activation_136[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_148 (Batch  (None, 8, 8, 1024)  4096        ['conv2d_148[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 8, 8, 1024)   0           ['batch_normalization_148[0][0]',\n",
      "                                                                  'activation_134[0][0]']         \n",
      "                                                                                                  \n",
      " activation_137 (Activation)    (None, 8, 8, 1024)   0           ['add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 4, 4, 512)    524800      ['activation_137[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_149 (Batch  (None, 4, 4, 512)   2048        ['conv2d_149[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_138 (Activation)    (None, 4, 4, 512)    0           ['batch_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)            (None, 4, 4, 512)    2359808     ['activation_138[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 4, 4, 512)   2048        ['conv2d_150[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_139 (Activation)    (None, 4, 4, 512)    0           ['batch_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 4, 4, 2048)   1050624     ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 4, 4, 2048)   2099200     ['activation_137[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 4, 4, 2048)  8192        ['conv2d_151[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 4, 4, 2048)  8192        ['conv2d_152[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 4, 4, 2048)   0           ['batch_normalization_151[0][0]',\n",
      "                                                                  'batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " activation_140 (Activation)    (None, 4, 4, 2048)   0           ['add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 4, 4, 512)    1049088     ['activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 4, 4, 512)   2048        ['conv2d_153[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_141 (Activation)    (None, 4, 4, 512)    0           ['batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 4, 4, 512)    2359808     ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 4, 4, 512)   2048        ['conv2d_154[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_142 (Activation)    (None, 4, 4, 512)    0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 4, 4, 2048)   1050624     ['activation_142[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 4, 4, 2048)  8192        ['conv2d_155[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 4, 4, 2048)   0           ['batch_normalization_155[0][0]',\n",
      "                                                                  'activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " activation_143 (Activation)    (None, 4, 4, 2048)   0           ['add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 4, 4, 512)    1049088     ['activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 4, 4, 512)   2048        ['conv2d_156[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_144 (Activation)    (None, 4, 4, 512)    0           ['batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 4, 4, 512)    2359808     ['activation_144[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 4, 4, 512)   2048        ['conv2d_157[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_145 (Activation)    (None, 4, 4, 512)    0           ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 4, 4, 2048)   1050624     ['activation_145[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 4, 4, 2048)  8192        ['conv2d_158[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 4, 4, 2048)   0           ['batch_normalization_158[0][0]',\n",
      "                                                                  'activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " activation_146 (Activation)    (None, 4, 4, 2048)   0           ['add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['activation_146[0][0]']         \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " feature_vector (Dense)         (None, 256)          524544      ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 8)            2056        ['feature_vector[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,114,312\n",
      "Trainable params: 24,061,192\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 7.0973 - accuracy: 0.1209\n",
      "Epoch 1: val_loss improved from inf to 7.06101, saving model to models\\model.h5\n",
      "242/242 [==============================] - 27s 96ms/step - loss: 7.0973 - accuracy: 0.1209 - val_loss: 7.0610 - val_accuracy: 0.1232\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 7.0599 - accuracy: 0.1239\n",
      "Epoch 2: val_loss improved from 7.06101 to 7.05894, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 95ms/step - loss: 7.0599 - accuracy: 0.1239 - val_loss: 7.0589 - val_accuracy: 0.1286\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 7.0553 - accuracy: 0.1298\n",
      "Epoch 3: val_loss did not improve from 7.05894\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 7.0553 - accuracy: 0.1298 - val_loss: 7.0686 - val_accuracy: 0.1226\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 7.0412 - accuracy: 0.1440\n",
      "Epoch 4: val_loss improved from 7.05894 to 5.67254, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 94ms/step - loss: 7.0412 - accuracy: 0.1440 - val_loss: 5.6725 - val_accuracy: 0.1472\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3565 - accuracy: 0.1586\n",
      "Epoch 5: val_loss improved from 5.67254 to 5.36168, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 94ms/step - loss: 5.3565 - accuracy: 0.1586 - val_loss: 5.3617 - val_accuracy: 0.1436\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3727 - accuracy: 0.1498\n",
      "Epoch 6: val_loss improved from 5.36168 to 5.35334, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 94ms/step - loss: 5.3727 - accuracy: 0.1498 - val_loss: 5.3533 - val_accuracy: 0.1581\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3145 - accuracy: 0.1769\n",
      "Epoch 7: val_loss did not improve from 5.35334\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.3145 - accuracy: 0.1769 - val_loss: 5.3921 - val_accuracy: 0.1466\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3229 - accuracy: 0.1789\n",
      "Epoch 8: val_loss improved from 5.35334 to 5.29991, saving model to models\\model.h5\n",
      "242/242 [==============================] - 24s 98ms/step - loss: 5.3229 - accuracy: 0.1789 - val_loss: 5.2999 - val_accuracy: 0.1761\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3034 - accuracy: 0.1944\n",
      "Epoch 9: val_loss did not improve from 5.29991\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.3034 - accuracy: 0.1944 - val_loss: 5.3535 - val_accuracy: 0.1605\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3062 - accuracy: 0.1939\n",
      "Epoch 10: val_loss did not improve from 5.29991\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.3062 - accuracy: 0.1939 - val_loss: 5.3245 - val_accuracy: 0.1719\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2429 - accuracy: 0.2012\n",
      "Epoch 11: val_loss did not improve from 5.29991\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2429 - accuracy: 0.2012 - val_loss: 5.3851 - val_accuracy: 0.1779\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2399 - accuracy: 0.2186\n",
      "Epoch 12: val_loss did not improve from 5.29991\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2399 - accuracy: 0.2186 - val_loss: 5.3836 - val_accuracy: 0.1803\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2253 - accuracy: 0.2155\n",
      "Epoch 13: val_loss did not improve from 5.29991\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2253 - accuracy: 0.2155 - val_loss: 5.7093 - val_accuracy: 0.1256\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2306 - accuracy: 0.2190\n",
      "Epoch 14: val_loss did not improve from 5.29991\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2306 - accuracy: 0.2190 - val_loss: 5.3537 - val_accuracy: 0.1959\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2187 - accuracy: 0.2278\n",
      "Epoch 15: val_loss improved from 5.29991 to 5.29756, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 94ms/step - loss: 5.2187 - accuracy: 0.2278 - val_loss: 5.2976 - val_accuracy: 0.2001\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2674 - accuracy: 0.1924\n",
      "Epoch 16: val_loss did not improve from 5.29756\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2674 - accuracy: 0.1924 - val_loss: 5.3683 - val_accuracy: 0.1496\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3072 - accuracy: 0.1893\n",
      "Epoch 17: val_loss improved from 5.29756 to 5.27345, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 94ms/step - loss: 5.3072 - accuracy: 0.1893 - val_loss: 5.2735 - val_accuracy: 0.1935\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2201 - accuracy: 0.2252\n",
      "Epoch 18: val_loss improved from 5.27345 to 5.25293, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 94ms/step - loss: 5.2201 - accuracy: 0.2252 - val_loss: 5.2529 - val_accuracy: 0.2025\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2563 - accuracy: 0.2066\n",
      "Epoch 19: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2563 - accuracy: 0.2066 - val_loss: 5.3900 - val_accuracy: 0.1490\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2689 - accuracy: 0.2033\n",
      "Epoch 20: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2689 - accuracy: 0.2033 - val_loss: 5.4458 - val_accuracy: 0.1304\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2241 - accuracy: 0.2127\n",
      "Epoch 21: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2241 - accuracy: 0.2127 - val_loss: 5.2841 - val_accuracy: 0.2157\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.1666 - accuracy: 0.2438\n",
      "Epoch 22: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.1666 - accuracy: 0.2438 - val_loss: 5.2652 - val_accuracy: 0.2230\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.1684 - accuracy: 0.2460\n",
      "Epoch 23: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.1684 - accuracy: 0.2460 - val_loss: 5.3335 - val_accuracy: 0.2188\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.1631 - accuracy: 0.2583\n",
      "Epoch 24: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.1631 - accuracy: 0.2583 - val_loss: 5.6651 - val_accuracy: 0.1250\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3798 - accuracy: 0.1317\n",
      "Epoch 25: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.3798 - accuracy: 0.1317 - val_loss: 5.3500 - val_accuracy: 0.1406\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3490 - accuracy: 0.1647\n",
      "Epoch 26: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 93ms/step - loss: 5.3490 - accuracy: 0.1647 - val_loss: 5.3808 - val_accuracy: 0.1538\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3009 - accuracy: 0.1906\n",
      "Epoch 27: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.3009 - accuracy: 0.1906 - val_loss: 5.3027 - val_accuracy: 0.1881\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3106 - accuracy: 0.1874\n",
      "Epoch 28: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.3106 - accuracy: 0.1874 - val_loss: 5.2929 - val_accuracy: 0.1779\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2307 - accuracy: 0.2292\n",
      "Epoch 29: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2307 - accuracy: 0.2292 - val_loss: 5.5298 - val_accuracy: 0.1881\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3133 - accuracy: 0.1785\n",
      "Epoch 30: val_loss did not improve from 5.25293\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.3133 - accuracy: 0.1785 - val_loss: 5.3656 - val_accuracy: 0.1665\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2721 - accuracy: 0.2050\n",
      "Epoch 31: val_loss improved from 5.25293 to 5.25287, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 94ms/step - loss: 5.2721 - accuracy: 0.2050 - val_loss: 5.2529 - val_accuracy: 0.2025\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2638 - accuracy: 0.1997\n",
      "Epoch 32: val_loss did not improve from 5.25287\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2638 - accuracy: 0.1997 - val_loss: 5.2561 - val_accuracy: 0.1995\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.1850 - accuracy: 0.2298\n",
      "Epoch 33: val_loss did not improve from 5.25287\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.1850 - accuracy: 0.2298 - val_loss: 5.5112 - val_accuracy: 0.1749\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2061 - accuracy: 0.2296\n",
      "Epoch 34: val_loss improved from 5.25287 to 5.23732, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 94ms/step - loss: 5.2061 - accuracy: 0.2296 - val_loss: 5.2373 - val_accuracy: 0.2248\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.1437 - accuracy: 0.2453\n",
      "Epoch 35: val_loss improved from 5.23732 to 5.21115, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 96ms/step - loss: 5.1437 - accuracy: 0.2453 - val_loss: 5.2111 - val_accuracy: 0.2194\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.1360 - accuracy: 0.2584\n",
      "Epoch 36: val_loss improved from 5.21115 to 5.14024, saving model to models\\model.h5\n",
      "242/242 [==============================] - 23s 94ms/step - loss: 5.1360 - accuracy: 0.2584 - val_loss: 5.1402 - val_accuracy: 0.2464\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.1304 - accuracy: 0.2549\n",
      "Epoch 37: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.1304 - accuracy: 0.2549 - val_loss: 5.3287 - val_accuracy: 0.1833\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.1769 - accuracy: 0.2491\n",
      "Epoch 38: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.1769 - accuracy: 0.2491 - val_loss: 5.4184 - val_accuracy: 0.2037\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2384 - accuracy: 0.2143\n",
      "Epoch 39: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 23s 95ms/step - loss: 5.2384 - accuracy: 0.2143 - val_loss: 5.4416 - val_accuracy: 0.1376\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2236 - accuracy: 0.2171\n",
      "Epoch 40: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2236 - accuracy: 0.2171 - val_loss: 5.2725 - val_accuracy: 0.2290\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.1982 - accuracy: 0.2403\n",
      "Epoch 41: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.1982 - accuracy: 0.2403 - val_loss: 5.2098 - val_accuracy: 0.2284\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.1259 - accuracy: 0.2588\n",
      "Epoch 42: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.1259 - accuracy: 0.2588 - val_loss: 5.2571 - val_accuracy: 0.2121\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2340 - accuracy: 0.2128\n",
      "Epoch 43: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 23s 95ms/step - loss: 5.2340 - accuracy: 0.2128 - val_loss: 5.3115 - val_accuracy: 0.1791\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2092 - accuracy: 0.2330\n",
      "Epoch 44: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2092 - accuracy: 0.2330 - val_loss: 5.2051 - val_accuracy: 0.2236\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3549 - accuracy: 0.1565\n",
      "Epoch 45: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 91ms/step - loss: 5.3549 - accuracy: 0.1565 - val_loss: 5.3714 - val_accuracy: 0.1298\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.3421 - accuracy: 0.1703\n",
      "Epoch 46: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 91ms/step - loss: 5.3421 - accuracy: 0.1703 - val_loss: 5.3570 - val_accuracy: 0.1689\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2872 - accuracy: 0.2028\n",
      "Epoch 47: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 91ms/step - loss: 5.2872 - accuracy: 0.2028 - val_loss: 5.3317 - val_accuracy: 0.1659\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2785 - accuracy: 0.2004\n",
      "Epoch 48: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 91ms/step - loss: 5.2785 - accuracy: 0.2004 - val_loss: 5.4014 - val_accuracy: 0.1526\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2961 - accuracy: 0.1927\n",
      "Epoch 49: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 91ms/step - loss: 5.2961 - accuracy: 0.1927 - val_loss: 5.2848 - val_accuracy: 0.1887\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 5.2129 - accuracy: 0.2279\n",
      "Epoch 50: val_loss did not improve from 5.14024\n",
      "242/242 [==============================] - 22s 92ms/step - loss: 5.2129 - accuracy: 0.2279 - val_loss: 5.2454 - val_accuracy: 0.2163\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def train_age():\n",
    "\tmodel = myModel()\n",
    "\tmodel.compile(optimizer='adam',  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\tmodel.summary()\n",
    "\thistory = model.fit(train_generator,\n",
    "                        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "                        validation_data=validation_generator, \n",
    "                        validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "                        epochs = 50, \n",
    "                        verbose=1, \n",
    "                        callbacks=[ModelCheckpoint('models/model.h5',monitor='val_loss',verbose=1,save_best_only=True)])\n",
    "\n",
    "train_age()\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652674e5-3f26-44f4-ae68-d6397660663f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
