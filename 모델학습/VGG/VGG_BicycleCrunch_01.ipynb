{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037f84ae-9b6b-4fd8-aa54-ebe006186b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7874 images belonging to 8 classes.\n",
      "Found 1691 images belonging to 8 classes.\n",
      "Found 1687 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "train_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\training'\n",
    "val_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\validation'\n",
    "test_dir = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\test'\n",
    "\n",
    "# ImageDataGenerator 초기화\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # 이미지를 0과 1 사이의 값으로 정규화\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터셋을 위한 제너레이터 생성\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b0477b7-0816-490d-b799-a1a7b1e6b83e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 4,719,616\n",
      "Non-trainable params: 9,995,072\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2097408   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,814,152\n",
      "Trainable params: 6,819,080\n",
      "Non-trainable params: 9,995,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# VGG16의 모든 층을 동결\n",
    "for layer in base_model.layers:\n",
    "    if layer.name == 'block5_conv1' or layer.name == 'block5_conv2':\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "       layer.trainable = False\n",
    "    \n",
    "base_model.summary()\n",
    " \n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "#model.add(layers.Dropout(0.1))  # 과적합 방지를 위한 드롭아웃 추가\n",
    "model.add(layers.Dense(8, activation='softmax'))  # 8개 레이블\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652674e5-3f26-44f4-ae68-d6397660663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "246/246 [==============================] - 13s 38ms/step - loss: 2.0500 - acc: 0.1655 - val_loss: 1.9700 - val_acc: 0.2200\n",
      "Epoch 2/25\n",
      "246/246 [==============================] - 9s 35ms/step - loss: 1.8994 - acc: 0.2406 - val_loss: 1.8377 - val_acc: 0.2578\n",
      "Epoch 3/25\n",
      "246/246 [==============================] - 9s 36ms/step - loss: 1.7856 - acc: 0.2915 - val_loss: 1.7689 - val_acc: 0.2969\n",
      "Epoch 4/25\n",
      "246/246 [==============================] - 9s 36ms/step - loss: 1.6341 - acc: 0.3507 - val_loss: 1.6769 - val_acc: 0.3359\n",
      "Epoch 5/25\n",
      "246/246 [==============================] - 9s 36ms/step - loss: 1.4810 - acc: 0.4185 - val_loss: 1.5851 - val_acc: 0.3918\n",
      "Epoch 6/25\n",
      "246/246 [==============================] - 9s 35ms/step - loss: 1.3157 - acc: 0.4901 - val_loss: 1.4846 - val_acc: 0.4243\n",
      "Epoch 7/25\n",
      "246/246 [==============================] - 9s 35ms/step - loss: 1.1565 - acc: 0.5584 - val_loss: 1.4118 - val_acc: 0.4633\n",
      "Epoch 8/25\n",
      "246/246 [==============================] - 9s 36ms/step - loss: 1.0112 - acc: 0.6162 - val_loss: 1.5159 - val_acc: 0.4519\n",
      "Epoch 9/25\n",
      "246/246 [==============================] - 9s 36ms/step - loss: 0.8824 - acc: 0.6700 - val_loss: 1.3402 - val_acc: 0.5144\n",
      "Epoch 10/25\n",
      "246/246 [==============================] - 9s 37ms/step - loss: 0.7498 - acc: 0.7173 - val_loss: 1.3203 - val_acc: 0.5325\n",
      "Epoch 11/25\n",
      "246/246 [==============================] - 9s 36ms/step - loss: 0.6366 - acc: 0.7711 - val_loss: 1.3087 - val_acc: 0.5487\n",
      "Epoch 12/25\n",
      "246/246 [==============================] - 9s 36ms/step - loss: 0.5616 - acc: 0.8039 - val_loss: 1.2436 - val_acc: 0.5745\n",
      "Epoch 13/25\n",
      "246/246 [==============================] - 9s 35ms/step - loss: 0.4863 - acc: 0.8281 - val_loss: 1.2701 - val_acc: 0.5721\n",
      "Epoch 14/25\n",
      "246/246 [==============================] - 9s 35ms/step - loss: 0.3969 - acc: 0.8614 - val_loss: 1.3296 - val_acc: 0.5919\n",
      "Epoch 15/25\n",
      "246/246 [==============================] - 9s 35ms/step - loss: 0.3261 - acc: 0.8880 - val_loss: 1.3678 - val_acc: 0.5823\n",
      "Epoch 16/25\n",
      "246/246 [==============================] - 9s 35ms/step - loss: 0.2921 - acc: 0.9005 - val_loss: 1.3819 - val_acc: 0.5944\n",
      "Epoch 17/25\n",
      "246/246 [==============================] - 9s 35ms/step - loss: 0.2473 - acc: 0.9151 - val_loss: 1.3183 - val_acc: 0.6070\n",
      "Epoch 17: early stopping\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 1.3093 - acc: 0.6484\n",
      "\n",
      "테스트 정확도: 0.6484375\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.000122),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# 모델 훈련\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,    \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=25,\n",
    "    callbacks=[early_stopping])\n",
    "\n",
    "# 모델 평가 (테스트 데이터셋)\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print('\\n테스트 정확도:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c13f8bf-6902-4369-aeda-5f68cabe7dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2097408   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,814,152\n",
      "Trainable params: 6,819,080\n",
      "Non-trainable params: 9,995,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad7ab4dc-1326-4f86-9113-ee157bab2980",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='vgg16_input'), name='vgg16_input', description=\"created by layer 'vgg16_input'\") at layer \"vgg16\". The following previous layers were accessed without issue: ['block1_conv1', 'block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m last_conv_layer \u001b[38;5;241m=\u001b[39m base_model\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock5_pool\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 예시로 block5_pool을 사용\u001b[39;00m\n\u001b[0;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39moutput  \u001b[38;5;66;03m# model의 최종 층의 출력\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m model_cam \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlast_conv_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# CAM 계산 함수\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cam\u001b[39m(img_path, model_cam, last_conv_output_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\functional.py:165\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    157\u001b[0m         [\n\u001b[0;32m    158\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    159\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    160\u001b[0m         ]\n\u001b[0;32m    161\u001b[0m     ):\n\u001b[0;32m    162\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    163\u001b[0m             inputs, outputs\n\u001b[0;32m    164\u001b[0m         )\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\functional.py:264\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_coordinates\u001b[38;5;241m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_map_graph_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\functional.py:1128\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39mkeras_inputs):\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(x) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m computable_tensors:\n\u001b[1;32m-> 1128\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1129\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph disconnected: cannot obtain value for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1130\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following previous layers were accessed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1132\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout issue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayers_with_complete_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1133\u001b[0m         )\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39moutputs):\n\u001b[0;32m   1135\u001b[0m     computable_tensors\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(x))\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='vgg16_input'), name='vgg16_input', description=\"created by layer 'vgg16_input'\") at layer \"vgg16\". The following previous layers were accessed without issue: ['block1_conv1', 'block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool']"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "# VGG16 모델 로드\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# VGG16의 모든 층을 동결\n",
    "for layer in base_model.layers:\n",
    "    if layer.name == 'block5_conv1' or layer.name == 'block5_conv2':\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Sequential 모델 생성 및 base_model 추가\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "#model.add(layers.Dropout(0.1))  # 과적합 방지를 위한 드롭아웃 추가\n",
    "model.add(layers.Dense(8, activation='softmax'))  # 8개 레이블\n",
    "\n",
    "# 함수형 API를 사용하여 새로운 모델 생성\n",
    "# 마지막 컨볼루션 블록의 출력과 최종 예측을 함께 반환\n",
    "last_conv_layer = base_model.get_layer('block5_pool')  # 예시로 block5_pool을 사용\n",
    "x = model.layers[-1].output  # model의 최종 층의 출력\n",
    "model_cam = Model(inputs=base_model.input, outputs=[last_conv_layer.output, x])\n",
    "\n",
    "# CAM 계산 함수\n",
    "def get_cam(img_path, model_cam, last_conv_output_index=0):\n",
    "    img = image.load_img(img_path, target_size=(128, 128))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x /= 255.0\n",
    "\n",
    "    # model.predict 호출 전 데이터 확인\n",
    "    print(x.shape)\n",
    "    \n",
    "    last_conv_output, preds = model_cam.predict(x)\n",
    "    # model.predict 호출 후 데이터 확인\n",
    "    print(last_conv_output.shape)\n",
    "    \n",
    "    # 위 출력 결과를 통해 last_conv_output의 형태를 확인하고 적절히 처리\n",
    "\n",
    "    \n",
    "    last_conv_output, preds = model_cam.predict(x)\n",
    "    last_conv_output = last_conv_output[0]  # 배치 차원 제거\n",
    "\n",
    "    class_idx = np.argmax(preds[0])\n",
    "    class_output = model.output[:, class_idx]\n",
    "    \n",
    "    # 분류 레이어의 가중치를 가져옵니다.\n",
    "    weights = model_cam.layers[-1].get_weights()[0][:, class_idx]\n",
    "    \n",
    "    # 마지막 컨볼루션 레이어의 출력에 대해 채널별로 가중치를 적용합니다.\n",
    "    cam = np.zeros(dtype=np.float32, shape=last_conv_output.shape[0:2])\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * last_conv_output[:, :, i]\n",
    "\n",
    "    # 결과적인 CAM을 이미지의 크기로 확대\n",
    "    cam = np.maximum(cam, 0)  # ReLU\n",
    "    cam = cv2.resize(cam, (128, 128))\n",
    "    cam = cam / np.max(cam)  # 정규화\n",
    "    return cam, preds\n",
    "\n",
    "\n",
    "# 이미지 경로\n",
    "img_path = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\test\\BicycleCrunch_505\\505-Z6_C-0000022.jpg'\n",
    "\n",
    "# CAM 계산 및 시각화\n",
    "cam, preds = get_cam(img_path, model_cam)\n",
    "img = image.load_img(img_path)\n",
    "img = image.img_to_array(img)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# 원본 이미지 출력\n",
    "plt.subplot(121)\n",
    "plt.imshow(img.astype('uint8'))\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "# CAM 오버레이 출력\n",
    "plt.subplot(122)\n",
    "plt.imshow(img.astype('uint8'), alpha=0.5)\n",
    "plt.imshow(cam, cmap='jet', alpha=0.5)  # CAM 오버레이\n",
    "plt.title(\"CAM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9220aa-c56b-4340-88fb-78eb9e9f10ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
