{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be0c880-cc8c-4335-8f0c-1b3224abef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7874 [array([0, 0, 0, ..., 1, 1, 1]), array([0, 0, 0, ..., 1, 1, 1]), array([0, 0, 0, ..., 1, 1, 1])]\n",
      "1691 3\n",
      "1687 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "train_folder = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\training'\n",
    "valid_folder = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\validation'\n",
    "test_folder = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\test'\n",
    "\n",
    "last_path = [[0,0,0],[1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,1],[1,0,1],[1,1,1]]\n",
    "prefix = [f\"{i:03d}\" for i in range(505, 513)]\n",
    "prefix_to_label = dict(zip(prefix, last_path))\n",
    "\n",
    "def process_dataset(root_folder):\n",
    "    image_paths = []\n",
    "    label_data = []\n",
    "    label_data_1 = []\n",
    "    label_data_2 = []\n",
    "    label_data_3 = []\n",
    "    for roots, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                # 파일 이름 분석을 위해 숫자만 추출\n",
    "                prefix = file[0:3]\n",
    "                \n",
    "                # 접두사에 따른 레이블 할당\n",
    "                label = prefix_to_label.get(prefix)\n",
    "                # 유효한 레이블이 있는 경우에만 리스트에 추가\n",
    "                if label is not None:\n",
    "                    image_paths.append(os.path.join(roots, file))\n",
    "                    label_data_1.append(label[0])\n",
    "                    label_data_2.append(label[1])\n",
    "                    label_data_3.append(label[2])\n",
    "\n",
    "    label_data.append(np.array(label_data_1))\n",
    "    label_data.append(np.array(label_data_2))\n",
    "    label_data.append(np.array(label_data_3))\n",
    "    return image_paths, label_data\n",
    "\n",
    "# 각각의 데이터셋에 대해 함수를 호출\n",
    "train_image_paths, train_label_data = process_dataset(train_folder)\n",
    "valid_image_paths, valid_label_data = process_dataset(valid_folder)\n",
    "test_image_paths, test_label_data = process_dataset(test_folder)\n",
    "\n",
    "# 필요에 따라 결과를 확인하거나 다른 처리를 수행\n",
    "print(len(train_image_paths), (train_label_data))\n",
    "print(len(valid_image_paths), len(valid_label_data))\n",
    "print(len(test_image_paths), len(test_label_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b87277-a1ac-47bf-80e9-a89fc97f0b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#이미지 전처리\n",
    "def resize_img(image_paths):\n",
    "    images_resized = []  # 리사이즈된 이미지를 저장할 리스트\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)  # 각 이미지 경로로부터 이미지를 읽음\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR에서 RGB로 색상 변환\n",
    "        image_resized = cv2.resize(image, (128, 128))  # 이미지 리사이즈\n",
    "        images_resized.append(image_resized)  # 결과 리스트에 추가\n",
    "    images_resized = np.array(images_resized) / 255.0  # numpy 배열로 변환 및 정규화\n",
    "    return images_resized\n",
    "\n",
    "train_image_resized = resize_img(train_image_paths)\n",
    "valid_image_resized = resize_img(valid_image_paths)\n",
    "test_image_resized = resize_img(test_image_paths)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b58b1e-89af-4686-a157-4df1dea76dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성    \n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "# base_model = tf.keras.applications.InceptionV3(input_tensor=input_tensor, \n",
    "#                                                weights=\"imagenet\", \n",
    "#                                                include_top=False, \n",
    "#                                                input_shape=(128, 128, 3))\n",
    "    \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "#x = Dropout(0.1)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "#x = Dropout(0.1)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "#x = Dropout(0.1)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "#x = Dropout(0.1)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "prediction1 = Dense(1, activation='sigmoid')(x)\n",
    "prediction2 = Dense(1, activation='sigmoid')(x)\n",
    "prediction3 = Dense(1, activation='sigmoid')(x)\n",
    "for layer in base_model.layers:\n",
    "    base_model.trainable = False\n",
    "for layer in base_model.layers[-9:]:\n",
    "    base_model.trainable = True\n",
    "# for layer in base_model.layers:\n",
    "#     base_model.trainable = False\n",
    "# for layer in base_model.layers[150:]:\n",
    "#     base_model.trainable = True\n",
    "model = Model(inputs=input_tensor, outputs=[prediction1, prediction2, prediction3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4bd30c-747e-4ca5-a17d-9b812d9507ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "247/247 [==============================] - 36s 116ms/step - loss: 0.6483 - dense_5_loss: 0.6714 - dense_6_loss: 0.6730 - dense_7_loss: 0.5929 - dense_5_accuracy: 0.5839 - dense_6_accuracy: 0.5712 - dense_7_accuracy: 0.6779 - val_loss: 0.6959 - val_dense_5_loss: 0.6933 - val_dense_6_loss: 0.6951 - val_dense_7_loss: 0.7000 - val_dense_5_accuracy: 0.5021 - val_dense_6_accuracy: 0.5021 - val_dense_7_accuracy: 0.4997\n",
      "Epoch 2/25\n",
      "247/247 [==============================] - 25s 100ms/step - loss: 0.5787 - dense_5_loss: 0.6293 - dense_6_loss: 0.6320 - dense_7_loss: 0.4579 - dense_5_accuracy: 0.6356 - dense_6_accuracy: 0.6393 - dense_7_accuracy: 0.7789 - val_loss: 0.7614 - val_dense_5_loss: 0.7264 - val_dense_6_loss: 0.7040 - val_dense_7_loss: 0.8654 - val_dense_5_accuracy: 0.5021 - val_dense_6_accuracy: 0.5021 - val_dense_7_accuracy: 0.4997\n",
      "Epoch 3/25\n",
      "247/247 [==============================] - 25s 102ms/step - loss: 0.5289 - dense_5_loss: 0.6013 - dense_6_loss: 0.5679 - dense_7_loss: 0.3934 - dense_5_accuracy: 0.6601 - dense_6_accuracy: 0.6960 - dense_7_accuracy: 0.8208 - val_loss: 0.9190 - val_dense_5_loss: 0.7591 - val_dense_6_loss: 0.7987 - val_dense_7_loss: 1.2524 - val_dense_5_accuracy: 0.5021 - val_dense_6_accuracy: 0.5021 - val_dense_7_accuracy: 0.4997\n",
      "Epoch 4/25\n",
      "247/247 [==============================] - 25s 103ms/step - loss: 0.4712 - dense_5_loss: 0.5575 - dense_6_loss: 0.4920 - dense_7_loss: 0.3352 - dense_5_accuracy: 0.6930 - dense_6_accuracy: 0.7568 - dense_7_accuracy: 0.8435 - val_loss: 0.6970 - val_dense_5_loss: 0.6317 - val_dense_6_loss: 0.7620 - val_dense_7_loss: 0.7189 - val_dense_5_accuracy: 0.6221 - val_dense_6_accuracy: 0.5145 - val_dense_7_accuracy: 0.5506\n",
      "Epoch 5/25\n",
      "247/247 [==============================] - 28s 113ms/step - loss: 0.4064 - dense_5_loss: 0.4862 - dense_6_loss: 0.4199 - dense_7_loss: 0.2865 - dense_5_accuracy: 0.7482 - dense_6_accuracy: 0.8038 - dense_7_accuracy: 0.8748 - val_loss: 0.4965 - val_dense_5_loss: 0.5628 - val_dense_6_loss: 0.5118 - val_dense_7_loss: 0.3929 - val_dense_5_accuracy: 0.6949 - val_dense_6_accuracy: 0.7534 - val_dense_7_accuracy: 0.8255\n",
      "Epoch 6/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.3314 - dense_5_loss: 0.4050 - dense_6_loss: 0.3402 - dense_7_loss: 0.2244 - dense_5_accuracy: 0.8072 - dense_6_accuracy: 0.8500 - dense_7_accuracy: 0.9073 - val_loss: 0.4740 - val_dense_5_loss: 0.5239 - val_dense_6_loss: 0.5587 - val_dense_7_loss: 0.3228 - val_dense_5_accuracy: 0.7321 - val_dense_6_accuracy: 0.7380 - val_dense_7_accuracy: 0.8622\n",
      "Epoch 7/25\n",
      "247/247 [==============================] - 27s 110ms/step - loss: 0.2653 - dense_5_loss: 0.3211 - dense_6_loss: 0.2703 - dense_7_loss: 0.1858 - dense_5_accuracy: 0.8583 - dense_6_accuracy: 0.8853 - dense_7_accuracy: 0.9249 - val_loss: 0.4690 - val_dense_5_loss: 0.5399 - val_dense_6_loss: 0.4843 - val_dense_7_loss: 0.3593 - val_dense_5_accuracy: 0.7357 - val_dense_6_accuracy: 0.7812 - val_dense_7_accuracy: 0.8652\n",
      "Epoch 8/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.2079 - dense_5_loss: 0.2478 - dense_6_loss: 0.2237 - dense_7_loss: 0.1390 - dense_5_accuracy: 0.9004 - dense_6_accuracy: 0.9081 - dense_7_accuracy: 0.9488 - val_loss: 0.6233 - val_dense_5_loss: 0.8634 - val_dense_6_loss: 0.5374 - val_dense_7_loss: 0.3890 - val_dense_5_accuracy: 0.7096 - val_dense_6_accuracy: 0.8001 - val_dense_7_accuracy: 0.8474\n",
      "Epoch 9/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.1675 - dense_5_loss: 0.1989 - dense_6_loss: 0.1734 - dense_7_loss: 0.1197 - dense_5_accuracy: 0.9209 - dense_6_accuracy: 0.9338 - dense_7_accuracy: 0.9564 - val_loss: 0.5276 - val_dense_5_loss: 0.6680 - val_dense_6_loss: 0.5044 - val_dense_7_loss: 0.3634 - val_dense_5_accuracy: 0.7824 - val_dense_6_accuracy: 0.8054 - val_dense_7_accuracy: 0.8687\n",
      "Epoch 10/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.1282 - dense_5_loss: 0.1505 - dense_6_loss: 0.1357 - dense_7_loss: 0.0910 - dense_5_accuracy: 0.9468 - dense_6_accuracy: 0.9472 - dense_7_accuracy: 0.9670 - val_loss: 0.5994 - val_dense_5_loss: 0.6460 - val_dense_6_loss: 0.6480 - val_dense_7_loss: 0.4889 - val_dense_5_accuracy: 0.7765 - val_dense_6_accuracy: 0.7842 - val_dense_7_accuracy: 0.8397\n",
      "Epoch 11/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.1096 - dense_5_loss: 0.1347 - dense_6_loss: 0.1134 - dense_7_loss: 0.0721 - dense_5_accuracy: 0.9515 - dense_6_accuracy: 0.9567 - dense_7_accuracy: 0.9737 - val_loss: 0.5625 - val_dense_5_loss: 0.6557 - val_dense_6_loss: 0.5980 - val_dense_7_loss: 0.4027 - val_dense_5_accuracy: 0.7629 - val_dense_6_accuracy: 0.8114 - val_dense_7_accuracy: 0.8776\n",
      "Epoch 12/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.0875 - dense_5_loss: 0.1016 - dense_6_loss: 0.0972 - dense_7_loss: 0.0591 - dense_5_accuracy: 0.9643 - dense_6_accuracy: 0.9643 - dense_7_accuracy: 0.9804 - val_loss: 0.6196 - val_dense_5_loss: 0.6121 - val_dense_6_loss: 0.6255 - val_dense_7_loss: 0.6238 - val_dense_5_accuracy: 0.7824 - val_dense_6_accuracy: 0.8013 - val_dense_7_accuracy: 0.8356\n",
      "Epoch 13/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.0805 - dense_5_loss: 0.0933 - dense_6_loss: 0.0872 - dense_7_loss: 0.0567 - dense_5_accuracy: 0.9651 - dense_6_accuracy: 0.9712 - dense_7_accuracy: 0.9802 - val_loss: 0.5482 - val_dense_5_loss: 0.6206 - val_dense_6_loss: 0.5971 - val_dense_7_loss: 0.4027 - val_dense_5_accuracy: 0.8084 - val_dense_6_accuracy: 0.8226 - val_dense_7_accuracy: 0.8805\n",
      "Epoch 14/25\n",
      "247/247 [==============================] - 27s 109ms/step - loss: 0.0797 - dense_5_loss: 0.0870 - dense_6_loss: 0.0877 - dense_7_loss: 0.0618 - dense_5_accuracy: 0.9694 - dense_6_accuracy: 0.9682 - dense_7_accuracy: 0.9774 - val_loss: 0.4593 - val_dense_5_loss: 0.4938 - val_dense_6_loss: 0.5230 - val_dense_7_loss: 0.3496 - val_dense_5_accuracy: 0.8326 - val_dense_6_accuracy: 0.8267 - val_dense_7_accuracy: 0.8805\n",
      "Epoch 15/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.0642 - dense_5_loss: 0.0630 - dense_6_loss: 0.0771 - dense_7_loss: 0.0529 - dense_5_accuracy: 0.9769 - dense_6_accuracy: 0.9713 - dense_7_accuracy: 0.9822 - val_loss: 0.5260 - val_dense_5_loss: 0.6097 - val_dense_6_loss: 0.5866 - val_dense_7_loss: 0.3539 - val_dense_5_accuracy: 0.8196 - val_dense_6_accuracy: 0.8078 - val_dense_7_accuracy: 0.8835\n",
      "Epoch 16/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.0519 - dense_5_loss: 0.0587 - dense_6_loss: 0.0570 - dense_7_loss: 0.0376 - dense_5_accuracy: 0.9818 - dense_6_accuracy: 0.9803 - dense_7_accuracy: 0.9876 - val_loss: 0.5120 - val_dense_5_loss: 0.6424 - val_dense_6_loss: 0.5205 - val_dense_7_loss: 0.3296 - val_dense_5_accuracy: 0.8131 - val_dense_6_accuracy: 0.8344 - val_dense_7_accuracy: 0.8995\n",
      "Epoch 17/25\n",
      "247/247 [==============================] - 26s 107ms/step - loss: 0.0453 - dense_5_loss: 0.0451 - dense_6_loss: 0.0572 - dense_7_loss: 0.0337 - dense_5_accuracy: 0.9851 - dense_6_accuracy: 0.9809 - dense_7_accuracy: 0.9897 - val_loss: 0.5131 - val_dense_5_loss: 0.6140 - val_dense_6_loss: 0.5645 - val_dense_7_loss: 0.3269 - val_dense_5_accuracy: 0.8143 - val_dense_6_accuracy: 0.8303 - val_dense_7_accuracy: 0.8959\n",
      "Epoch 18/25\n",
      "247/247 [==============================] - 26s 106ms/step - loss: 0.0482 - dense_5_loss: 0.0447 - dense_6_loss: 0.0600 - dense_7_loss: 0.0410 - dense_5_accuracy: 0.9858 - dense_6_accuracy: 0.9797 - dense_7_accuracy: 0.9878 - val_loss: 0.6332 - val_dense_5_loss: 0.8363 - val_dense_6_loss: 0.5967 - val_dense_7_loss: 0.3990 - val_dense_5_accuracy: 0.7859 - val_dense_6_accuracy: 0.8196 - val_dense_7_accuracy: 0.8764\n",
      "Epoch 19/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.0723 - dense_5_loss: 0.0934 - dense_6_loss: 0.0646 - dense_7_loss: 0.0519 - dense_5_accuracy: 0.9704 - dense_6_accuracy: 0.9785 - dense_7_accuracy: 0.9818 - val_loss: 0.5140 - val_dense_5_loss: 0.5890 - val_dense_6_loss: 0.5703 - val_dense_7_loss: 0.3577 - val_dense_5_accuracy: 0.8084 - val_dense_6_accuracy: 0.8208 - val_dense_7_accuracy: 0.8965\n",
      "Epoch 20/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.0489 - dense_5_loss: 0.0478 - dense_6_loss: 0.0575 - dense_7_loss: 0.0417 - dense_5_accuracy: 0.9841 - dense_6_accuracy: 0.9796 - dense_7_accuracy: 0.9869 - val_loss: 0.5320 - val_dense_5_loss: 0.6606 - val_dense_6_loss: 0.5676 - val_dense_7_loss: 0.3251 - val_dense_5_accuracy: 0.8025 - val_dense_6_accuracy: 0.8114 - val_dense_7_accuracy: 0.8906\n",
      "Epoch 21/25\n",
      "247/247 [==============================] - 26s 105ms/step - loss: 0.0353 - dense_5_loss: 0.0429 - dense_6_loss: 0.0376 - dense_7_loss: 0.0229 - dense_5_accuracy: 0.9858 - dense_6_accuracy: 0.9868 - dense_7_accuracy: 0.9925 - val_loss: 0.6890 - val_dense_5_loss: 0.6926 - val_dense_6_loss: 0.8774 - val_dense_7_loss: 0.4958 - val_dense_5_accuracy: 0.8285 - val_dense_6_accuracy: 0.8143 - val_dense_7_accuracy: 0.8829\n",
      "Epoch 21: early stopping\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.7025 - dense_5_loss: 0.6928 - dense_6_loss: 0.8677 - dense_7_loss: 0.5504 - dense_5_accuracy: 0.8162 - dense_6_accuracy: 0.8151 - dense_7_accuracy: 0.8666\n",
      "\n",
      "총 테스트 손실: 0.7025355696678162\n",
      "출력1 테스트 손실: 0.692810595035553 출력1 테스트 정확도: 0.8162418603897095\n",
      "출력2 테스트 손실: 0.8676806092262268 출력2 테스트 정확도: 0.815056324005127\n",
      "출력3 테스트 손실: 0.5503570437431335 출력3 테스트 정확도: 0.8666271567344666\n"
     ]
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(monitor='val_loss', patience=7, mode='min', verbose=1)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0002),\n",
    "              loss=['binary_crossentropy','binary_crossentropy','binary_crossentropy'], loss_weights=[0.4, 0.3, 0.3],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(train_image_resized, \n",
    "          train_label_data, \n",
    "          validation_data=(valid_image_resized, valid_label_data), \n",
    "          epochs=25, \n",
    "          batch_size=32,\n",
    "          callbacks=[earlystopping])\n",
    "\n",
    "# 모델 평가 (테스트 데이터셋)\n",
    "eval_results = model.evaluate(test_image_resized, test_label_data)\n",
    "print('\\n총 테스트 손실:', eval_results[0])\n",
    "print('출력1 테스트 손실:', eval_results[1], '출력1 테스트 정확도:', eval_results[4])\n",
    "print('출력2 테스트 손실:', eval_results[2], '출력2 테스트 정확도:', eval_results[5])\n",
    "print('출력3 테스트 손실:', eval_results[3], '출력3 테스트 정확도:', eval_results[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c73b61f-0d5c-43f7-8992-6b354be84c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\AImodel\\models\\Face-ResNet-BicycleCrunch-multilabel-model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\AImodel\\models\\Face-ResNet-BicycleCrunch-multilabel-model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(r'E:\\AImodel\\models\\Face-ResNet-BicycleCrunch-multilabel-model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3aaa85-f124-44e7-a6b4-b31ceefb0bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
