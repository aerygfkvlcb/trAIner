{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037f84ae-9b6b-4fd8-aa54-ebe006186b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7775 images belonging to 8 classes.\n",
      "Found 1670 images belonging to 8 classes.\n",
      "Found 1667 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "train_dir = r'E:\\AI\\dataset_skeleton_sep\\side\\BicycleCrunch\\training'\n",
    "val_dir = r'E:\\AI\\dataset_skeleton_sep\\side\\BicycleCrunch\\validation'\n",
    "test_dir = r'E:\\AI\\dataset_skeleton_sep\\side\\BicycleCrunch\\test'\n",
    "\n",
    "# ImageDataGenerator 초기화\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # 이미지를 0과 1 사이의 값으로 정규화\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터셋을 위한 제너레이터 생성\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea49f2b-a228-497d-ba9a-f5d120443afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95709e65-3d73-4157-bdb1-36ea1c21dfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from random_search\\CNN_hyperparam_opt\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "tensorboard_callback = TensorBoard(log_dir=r\"E:\\AInotes\\자세교정\\모델학습\\ResNet\\grid_search\")\n",
    "\n",
    "params_grid = {\n",
    "    'learning_rate': [1e-4, 1e-3],\n",
    "    'units': [256, 512]\n",
    "}\n",
    "\n",
    "# 모델을 빌드하는 함수\n",
    "def build_and_train_model(learning_rate, units):\n",
    "    RN50_2 = tf.keras.applications.resnet_v2.ResNet50V2(weights=\"imagenet\",\n",
    "                                                         include_top=False, \n",
    "                                                         input_shape=(128, 128, 3))\n",
    "    RN50_2.trainable = True\n",
    "\n",
    "    model = models.Sequential(name=\"ResNet50v2_RT\")\n",
    "    model.add(RN50_2)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(units=units, activation='relu'))\n",
    "    model.add(layers.Dense(8, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_generator,\n",
    "                        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "                        validation_data=validation_generator, \n",
    "                        validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "                        epochs=25,\n",
    "                        callbacks=[early_stopping, tensorboard_callback])\n",
    "    return model, history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a43c18dc-2a64-4c4f-95a8-d2ded0404978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 33s]\n",
      "val_accuracy: 0.12860576808452606\n",
      "\n",
      "Best val_accuracy So Far: 0.6231971383094788\n",
      "Total elapsed time: 00h 20m 22s\n",
      "Epoch 1/25\n",
      "485/485 [==============================] - 27s 50ms/step - loss: 2.0767 - accuracy: 0.1770 - val_loss: 2.0832 - val_accuracy: 0.2103\n",
      "Epoch 2/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 1.7961 - accuracy: 0.2771 - val_loss: 1.9804 - val_accuracy: 0.2272\n",
      "Epoch 3/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 1.5682 - accuracy: 0.3683 - val_loss: 1.6257 - val_accuracy: 0.3371\n",
      "Epoch 4/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 1.3362 - accuracy: 0.4716 - val_loss: 1.6919 - val_accuracy: 0.3870\n",
      "Epoch 5/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 1.1545 - accuracy: 0.5465 - val_loss: 1.3723 - val_accuracy: 0.4826\n",
      "Epoch 6/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 0.9725 - accuracy: 0.6217 - val_loss: 1.3420 - val_accuracy: 0.5096\n",
      "Epoch 7/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 0.7718 - accuracy: 0.7108 - val_loss: 1.4823 - val_accuracy: 0.5066\n",
      "Epoch 8/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 0.6664 - accuracy: 0.7581 - val_loss: 1.4104 - val_accuracy: 0.5409\n",
      "Epoch 9/25\n",
      "485/485 [==============================] - 24s 50ms/step - loss: 0.5166 - accuracy: 0.8167 - val_loss: 1.3525 - val_accuracy: 0.5703\n",
      "Epoch 10/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 0.4268 - accuracy: 0.8487 - val_loss: 1.2716 - val_accuracy: 0.5974\n",
      "Epoch 11/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 0.3550 - accuracy: 0.8732 - val_loss: 1.5139 - val_accuracy: 0.5823\n",
      "Epoch 12/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 0.3022 - accuracy: 0.8974 - val_loss: 1.4880 - val_accuracy: 0.5980\n",
      "Epoch 13/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 0.2439 - accuracy: 0.9153 - val_loss: 1.3516 - val_accuracy: 0.6070\n",
      "Epoch 14/25\n",
      "485/485 [==============================] - 24s 49ms/step - loss: 0.2147 - accuracy: 0.9298 - val_loss: 1.7219 - val_accuracy: 0.5847\n",
      "Epoch 15/25\n",
      "326/485 [===================>..........] - ETA: 7s - loss: 0.2000 - accuracy: 0.9346"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 3.00 MiB for an array with shape (16, 128, 128, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 3.00 MiB for an array with shape (16, 128, 128, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 3.00 MiB for an array with shape (16, 128, 128, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 3.00 MiB for an array with shape (16, 128, 128, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_145963]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mbuild(best_hps)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 3.00 MiB for an array with shape (16, 128, 128, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 3.00 MiB for an array with shape (16, 128, 128, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  MemoryError: Unable to allocate 3.00 MiB for an array with shape (16, 128, 128, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\ajhoo\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\ajhoo\\anaconda3\\envs\\tensorGPU\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 222, in _get_batches_of_transformed_samples\n    batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=self.dtype)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 3.00 MiB for an array with shape (16, 128, 128, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_145963]"
     ]
    }
   ],
   "source": [
    "for params in ParameterGrid(params_grid):\n",
    "    print(\"Training with params:\", params)\n",
    "    model, history = build_and_train_model(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652674e5-3f26-44f4-ae68-d6397660663f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
