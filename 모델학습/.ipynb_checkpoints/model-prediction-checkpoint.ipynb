{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a07171-d825-42ed-aac8-03b0aa756d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import resnet50, ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1e6b0b-9644-496d-a893-4554fedc63fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128, 128, 3)\n",
      "<dtype: 'float32'>\n",
      "(None, 5)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "json_path = 'E:/AInotes/자세교정/모델학습/label_data.json'\n",
    "exercise_name = 'SideLunge'\n",
    "model = tf.keras.models.load_model(r'E:\\AImodel\\models\\Multilabel\\SideLunge-face-multilabel-model02.h5')\n",
    "dir_path = r'E:\\AImodel\\models\\Multilabel\\test-images'\n",
    "\n",
    "print(model.input.shape)\n",
    "print(model.input.dtype)\n",
    "print(model.output.shape)\n",
    "print(model.output.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbdc504a-034f-457c-a382-fb29491a6fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.9399204e-03 6.2750829e-03 8.6539626e-01 9.9411124e-01 9.8472089e-01]\n",
      " [1.0739210e-02 2.3694688e-02 7.4418169e-01 9.8819357e-01 1.1536276e-01]\n",
      " [1.2382161e-04 2.5939141e-06 9.9999094e-01 9.9040169e-01 1.4724855e-06]\n",
      " [2.7513268e-04 1.4443079e-02 9.8895371e-01 5.2748615e-05 2.9677585e-05]\n",
      " [2.2980163e-04 2.8115483e-03 9.9819982e-01 5.1024725e-04 1.2944587e-05]\n",
      " [3.7853295e-01 8.5693851e-02 9.0782350e-01 7.0058994e-02 3.3463482e-02]\n",
      " [1.9462183e-02 2.8352885e-02 5.5765599e-01 9.3619961e-01 7.5606006e-01]\n",
      " [1.0946807e-02 3.0125682e-03 9.7446662e-01 9.8395777e-01 3.4728567e-03]\n",
      " [3.1946630e-03 2.3967709e-01 8.5693687e-01 3.5231858e-03 1.8724744e-03]\n",
      " [1.6572982e-02 2.7430596e-02 9.4105476e-01 9.0065634e-01 3.6600675e-02]\n",
      " [1.5608992e-01 4.5630825e-03 9.9277747e-01 4.6808773e-01 7.3866444e-03]\n",
      " [1.2887877e-01 2.7356301e-02 9.4377881e-01 8.9647722e-01 3.1931475e-01]\n",
      " [2.7306992e-01 6.4496475e-01 5.7507885e-01 2.3305835e-01 2.8867665e-01]\n",
      " [2.3772953e-05 2.6211484e-07 9.9999678e-01 9.9999285e-01 4.6563133e-07]\n",
      " [1.6221182e-03 1.4809828e-02 9.9256706e-01 8.8185357e-04 1.1662727e-04]\n",
      " [1.6146680e-04 2.0551364e-01 9.0202677e-01 2.1984557e-02 8.6648492e-05]\n",
      " [2.2249684e-02 1.0137668e-02 9.2949027e-01 9.9014843e-01 1.1394638e-02]\n",
      " [3.5286330e-02 1.3926366e-03 8.9743453e-01 9.9729222e-01 9.6118760e-01]\n",
      " [1.1240149e-01 2.6009528e-02 9.2248225e-01 8.4336489e-01 5.1330607e-02]\n",
      " [5.5204862e-04 4.1878996e-03 9.9497378e-01 9.7722560e-01 7.6875570e-03]\n",
      " [3.2823898e-03 5.5975997e-01 4.8089686e-01 9.2217557e-02 9.5661515e-03]\n",
      " [5.2537126e-03 6.4526275e-02 9.6655822e-01 2.2494786e-03 5.5702066e-04]\n",
      " [6.0777464e-03 9.4072688e-03 1.2309068e-01 9.9509591e-01 2.6761170e-02]]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image_path, target_size=(128, 128)): #이미지 파일을 불러와 전처리하는 함수\n",
    "    img = image.load_img(image_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # 모델 예측을 위해 차원 확장\n",
    "    img_array /= 255.0  # 이미지를 0과 1 사이로 스케일링\n",
    "    return img_array\n",
    "\n",
    "\n",
    "def load_and_preprocess_from_directory(directory_path, target_size=(128, 128)): # 지정된 디렉토리 내의 모든 이미지를 불러와 전처리하는 함수\n",
    "    processed_images = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img = preprocess_image(file_path, target_size=target_size)\n",
    "            processed_images.append(img)\n",
    "    return np.vstack(processed_images)  # 전처리된 이미지들을 하나의 numpy 배열로 합침\n",
    "\n",
    "\n",
    "def apply_sliding_window_to_predictions(predictions, window_size=5, method='mean'): # 2D 예측 결과 배열에 대해 슬라이딩 윈도우를 적용하는 함수\n",
    "    num_classes = predictions.shape[1]  # 클래스 수\n",
    "    smoothed_predictions = np.zeros_like(predictions)\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        class_predictions = predictions[:, class_idx]  # 현재 클래스에 대한 모든 예측값\n",
    "        # 각 예측값에 대해 슬라이딩 윈도우 적용\n",
    "        for i in range(len(class_predictions)):\n",
    "            start_idx = max(0, i - window_size // 2)\n",
    "            end_idx = min(len(class_predictions), i + window_size // 2 + 1)\n",
    "            window = class_predictions[start_idx:end_idx]\n",
    "            if method == 'mean':\n",
    "                smoothed_value = np.mean(window)\n",
    "            elif method == 'median':\n",
    "                smoothed_value = np.median(window)\n",
    "            else:\n",
    "                raise ValueError(\"Method should be 'mean' or 'median'\")\n",
    "            smoothed_predictions[i, class_idx] = smoothed_value\n",
    "    \n",
    "    return smoothed_predictions\n",
    "\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "def get_prefix_to_label(file_path, exercise_name):\n",
    "    data = load_json_file(file_path)\n",
    "    result = (data.get(exercise_name))\n",
    "    prefix = data.get(exercise_name)['prefix']\n",
    "    label = data.get(exercise_name)['last_path']\n",
    "    prefix_to_label = dict(zip(prefix, label))\n",
    "    return prefix_to_label\n",
    "    \n",
    "\n",
    "def print_predictions(predictions, exercise_name, json_path, threshold=0.5):\n",
    "    # JSON 파일 로드 및 라벨 길이 구하기\n",
    "    data = load_json_file(json_path)\n",
    "    label_length = len(data[exercise_name]['last_path'][0])\n",
    "    \n",
    "    # 각 라벨마다 T, F의 개수를 저장할 딕셔너리 동적으로 초기화\n",
    "    label_counts = {i+1: {'T': 0, 'F': 0} for i in range(label_length)}\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        labels = (prediction > threshold).astype(int)\n",
    "        label_str = ','.join(['T' if label == 1 else 'F' for label in labels])\n",
    "        print(f\"Image {i+1}: {label_str}\")\n",
    "        \n",
    "        # 각 라벨마다 T, F의 개수를 계산\n",
    "        for label_index, label in enumerate(labels, start=1):\n",
    "            if label == 1:\n",
    "                label_counts[label_index]['T'] += 1\n",
    "            else:\n",
    "                label_counts[label_index]['F'] += 1\n",
    "    \n",
    "    # 각 라벨에 대한 총합 출력\n",
    "    for label_index in label_counts:\n",
    "        print(f\"Label {label_index}: T = {label_counts[label_index]['T']}, F = {label_counts[label_index]['F']}\")\n",
    "\n",
    "\n",
    "preprocessed_images = load_and_preprocess_from_directory(dir_path)\n",
    "predictions = model.predict(preprocessed_images, verbose=0)\n",
    "# 예측 결과 출력\n",
    "print(predictions)\n",
    "smoothed_predictions = apply_sliding_window_to_predictions(predictions, window_size=5, method='mean')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "324468ba-96b1-4485-b6dc-e750304e4602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델은 총 5개의 클래스를 가지고 있습니다.\n",
      "Image 1:\n",
      "  class1: 0.01%\n",
      "  class2: 0.01%\n",
      "  class3: 0.87%\n",
      "  class4: 0.99%\n",
      "  class5: 0.98%\n",
      "\n",
      "Image 2:\n",
      "  class1: 0.01%\n",
      "  class2: 0.02%\n",
      "  class3: 0.74%\n",
      "  class4: 0.99%\n",
      "  class5: 0.12%\n",
      "\n",
      "Image 3:\n",
      "  class1: 0.00%\n",
      "  class2: 0.00%\n",
      "  class3: 1.00%\n",
      "  class4: 0.99%\n",
      "  class5: 0.00%\n",
      "\n",
      "Image 4:\n",
      "  class1: 0.00%\n",
      "  class2: 0.01%\n",
      "  class3: 0.99%\n",
      "  class4: 0.00%\n",
      "  class5: 0.00%\n",
      "\n",
      "Image 5:\n",
      "  class1: 0.00%\n",
      "  class2: 0.00%\n",
      "  class3: 1.00%\n",
      "  class4: 0.00%\n",
      "  class5: 0.00%\n",
      "\n",
      "Image 6:\n",
      "  class1: 0.38%\n",
      "  class2: 0.09%\n",
      "  class3: 0.91%\n",
      "  class4: 0.07%\n",
      "  class5: 0.03%\n",
      "\n",
      "Image 7:\n",
      "  class1: 0.02%\n",
      "  class2: 0.03%\n",
      "  class3: 0.56%\n",
      "  class4: 0.94%\n",
      "  class5: 0.76%\n",
      "\n",
      "Image 8:\n",
      "  class1: 0.01%\n",
      "  class2: 0.00%\n",
      "  class3: 0.97%\n",
      "  class4: 0.98%\n",
      "  class5: 0.00%\n",
      "\n",
      "Image 9:\n",
      "  class1: 0.00%\n",
      "  class2: 0.24%\n",
      "  class3: 0.86%\n",
      "  class4: 0.00%\n",
      "  class5: 0.00%\n",
      "\n",
      "Image 10:\n",
      "  class1: 0.02%\n",
      "  class2: 0.03%\n",
      "  class3: 0.94%\n",
      "  class4: 0.90%\n",
      "  class5: 0.04%\n",
      "\n",
      "Image 11:\n",
      "  class1: 0.16%\n",
      "  class2: 0.00%\n",
      "  class3: 0.99%\n",
      "  class4: 0.47%\n",
      "  class5: 0.01%\n",
      "\n",
      "Image 12:\n",
      "  class1: 0.13%\n",
      "  class2: 0.03%\n",
      "  class3: 0.94%\n",
      "  class4: 0.90%\n",
      "  class5: 0.32%\n",
      "\n",
      "Image 13:\n",
      "  class1: 0.27%\n",
      "  class2: 0.64%\n",
      "  class3: 0.58%\n",
      "  class4: 0.23%\n",
      "  class5: 0.29%\n",
      "\n",
      "Image 14:\n",
      "  class1: 0.00%\n",
      "  class2: 0.00%\n",
      "  class3: 1.00%\n",
      "  class4: 1.00%\n",
      "  class5: 0.00%\n",
      "\n",
      "Image 15:\n",
      "  class1: 0.00%\n",
      "  class2: 0.01%\n",
      "  class3: 0.99%\n",
      "  class4: 0.00%\n",
      "  class5: 0.00%\n",
      "\n",
      "Image 16:\n",
      "  class1: 0.00%\n",
      "  class2: 0.21%\n",
      "  class3: 0.90%\n",
      "  class4: 0.02%\n",
      "  class5: 0.00%\n",
      "\n",
      "Image 17:\n",
      "  class1: 0.02%\n",
      "  class2: 0.01%\n",
      "  class3: 0.93%\n",
      "  class4: 0.99%\n",
      "  class5: 0.01%\n",
      "\n",
      "Image 18:\n",
      "  class1: 0.04%\n",
      "  class2: 0.00%\n",
      "  class3: 0.90%\n",
      "  class4: 1.00%\n",
      "  class5: 0.96%\n",
      "\n",
      "Image 19:\n",
      "  class1: 0.11%\n",
      "  class2: 0.03%\n",
      "  class3: 0.92%\n",
      "  class4: 0.84%\n",
      "  class5: 0.05%\n",
      "\n",
      "Image 20:\n",
      "  class1: 0.00%\n",
      "  class2: 0.00%\n",
      "  class3: 0.99%\n",
      "  class4: 0.98%\n",
      "  class5: 0.01%\n",
      "\n",
      "Image 21:\n",
      "  class1: 0.00%\n",
      "  class2: 0.56%\n",
      "  class3: 0.48%\n",
      "  class4: 0.09%\n",
      "  class5: 0.01%\n",
      "\n",
      "Image 22:\n",
      "  class1: 0.01%\n",
      "  class2: 0.06%\n",
      "  class3: 0.97%\n",
      "  class4: 0.00%\n",
      "  class5: 0.00%\n",
      "\n",
      "Image 23:\n",
      "  class1: 0.01%\n",
      "  class2: 0.01%\n",
      "  class3: 0.12%\n",
      "  class4: 1.00%\n",
      "  class5: 0.03%\n",
      "\n",
      "Image 1: F,F,T,T,T\n",
      "Image 2: F,F,T,T,F\n",
      "Image 3: F,F,T,T,F\n",
      "Image 4: F,F,T,F,F\n",
      "Image 5: F,F,T,F,F\n",
      "Image 6: F,F,T,F,F\n",
      "Image 7: F,F,T,T,T\n",
      "Image 8: F,F,T,T,F\n",
      "Image 9: F,F,T,F,F\n",
      "Image 10: F,F,T,T,F\n",
      "Image 11: F,F,T,F,F\n",
      "Image 12: F,F,T,T,F\n",
      "Image 13: F,T,T,F,F\n",
      "Image 14: F,F,T,T,F\n",
      "Image 15: F,F,T,F,F\n",
      "Image 16: F,F,T,F,F\n",
      "Image 17: F,F,T,T,F\n",
      "Image 18: F,F,T,T,T\n",
      "Image 19: F,F,T,T,F\n",
      "Image 20: F,F,T,T,F\n",
      "Image 21: F,T,F,F,F\n",
      "Image 22: F,F,T,F,F\n",
      "Image 23: F,F,F,T,F\n",
      "Label 1: T = 0, F = 23\n",
      "Label 2: T = 2, F = 21\n",
      "Label 3: T = 21, F = 2\n",
      "Label 4: T = 13, F = 10\n",
      "Label 5: T = 3, F = 20\n"
     ]
    }
   ],
   "source": [
    "# 모델의 출력층에 접근하여 클래스의 개수 얻기\n",
    "output_layer = model.layers[-1]  # 모델의 마지막 층 (출력층)을 가져옴\n",
    "num_classes = output_layer.units  # 출력층의 유닛 수를 가져옴, 이는 클래스의 수와 동일\n",
    "\n",
    "print(f'모델은 총 {num_classes}개의 클래스를 가지고 있습니다.')\n",
    "class_labels = []\n",
    "# 클래스 라벨 정의 (예: num_classes 개의 클래스)\n",
    "for i in range(num_classes):\n",
    "    class_labels.append(f'class{i+1}')\n",
    "\n",
    "# 예를 들어, num_classes가 3이라면 class_labels는 ['class1', 'cd lass2', 'class3']이 됩니다.\n",
    "\n",
    "\n",
    "# predictions 배열에서 각 입력에 대한 모든 클래스의 확률 출력\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f'Image {i+1}:')\n",
    "    for j, class_label in enumerate(class_labels):\n",
    "        print(f'  {class_label}: {prediction[j]:.2f}%')\n",
    "    print()  # 각 이미지의 예측 결과 사이에 공백 추가\n",
    "\n",
    "\n",
    "print_predictions(predictions, exercise_name, json_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468207e4-751e-4602-806a-dc83d02b18fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델은 총 5개의 클래스를 가지고 있습니다.\n",
      "Image 1:\n",
      "  class1: 0.01%\n",
      "  class2: 0.01%\n",
      "  class3: 0.87%\n",
      "  class4: 0.99%\n",
      "  class5: 0.37%\n",
      "\n",
      "Image 2:\n",
      "  class1: 0.00%\n",
      "  class2: 0.01%\n",
      "  class3: 0.90%\n",
      "  class4: 0.74%\n",
      "  class5: 0.28%\n",
      "\n",
      "Image 3:\n",
      "  class1: 0.00%\n",
      "  class2: 0.01%\n",
      "  class3: 0.92%\n",
      "  class4: 0.59%\n",
      "  class5: 0.22%\n",
      "\n",
      "Image 4:\n",
      "  class1: 0.08%\n",
      "  class2: 0.03%\n",
      "  class3: 0.93%\n",
      "  class4: 0.41%\n",
      "  class5: 0.03%\n",
      "\n",
      "Image 5:\n",
      "  class1: 0.08%\n",
      "  class2: 0.03%\n",
      "  class3: 0.89%\n",
      "  class4: 0.40%\n",
      "  class5: 0.16%\n",
      "\n",
      "Image 6:\n",
      "  class1: 0.08%\n",
      "  class2: 0.03%\n",
      "  class3: 0.89%\n",
      "  class4: 0.40%\n",
      "  class5: 0.16%\n",
      "\n",
      "Image 7:\n",
      "  class1: 0.08%\n",
      "  class2: 0.07%\n",
      "  class3: 0.86%\n",
      "  class4: 0.40%\n",
      "  class5: 0.16%\n",
      "\n",
      "Image 8:\n",
      "  class1: 0.09%\n",
      "  class2: 0.08%\n",
      "  class3: 0.85%\n",
      "  class4: 0.58%\n",
      "  class5: 0.17%\n",
      "\n",
      "Image 9:\n",
      "  class1: 0.04%\n",
      "  class2: 0.06%\n",
      "  class3: 0.86%\n",
      "  class4: 0.66%\n",
      "  class5: 0.16%\n",
      "\n",
      "Image 10:\n",
      "  class1: 0.06%\n",
      "  class2: 0.06%\n",
      "  class3: 0.94%\n",
      "  class4: 0.65%\n",
      "  class5: 0.07%\n",
      "\n",
      "Image 11:\n",
      "  class1: 0.12%\n",
      "  class2: 0.19%\n",
      "  class3: 0.86%\n",
      "  class4: 0.50%\n",
      "  class5: 0.13%\n",
      "\n",
      "Image 12:\n",
      "  class1: 0.11%\n",
      "  class2: 0.14%\n",
      "  class3: 0.89%\n",
      "  class4: 0.70%\n",
      "  class5: 0.13%\n",
      "\n",
      "Image 13:\n",
      "  class1: 0.11%\n",
      "  class2: 0.14%\n",
      "  class3: 0.90%\n",
      "  class4: 0.52%\n",
      "  class5: 0.12%\n",
      "\n",
      "Image 14:\n",
      "  class1: 0.08%\n",
      "  class2: 0.18%\n",
      "  class3: 0.88%\n",
      "  class4: 0.43%\n",
      "  class5: 0.12%\n",
      "\n",
      "Image 15:\n",
      "  class1: 0.06%\n",
      "  class2: 0.18%\n",
      "  class3: 0.88%\n",
      "  class4: 0.45%\n",
      "  class5: 0.06%\n",
      "\n",
      "Image 16:\n",
      "  class1: 0.01%\n",
      "  class2: 0.05%\n",
      "  class3: 0.94%\n",
      "  class4: 0.60%\n",
      "  class5: 0.19%\n",
      "\n",
      "Image 17:\n",
      "  class1: 0.03%\n",
      "  class2: 0.05%\n",
      "  class3: 0.93%\n",
      "  class4: 0.57%\n",
      "  class5: 0.20%\n",
      "\n",
      "Image 18:\n",
      "  class1: 0.03%\n",
      "  class2: 0.05%\n",
      "  class3: 0.93%\n",
      "  class4: 0.77%\n",
      "  class5: 0.21%\n",
      "\n",
      "Image 19:\n",
      "  class1: 0.03%\n",
      "  class2: 0.12%\n",
      "  class3: 0.85%\n",
      "  class4: 0.78%\n",
      "  class5: 0.21%\n",
      "\n",
      "Image 20:\n",
      "  class1: 0.03%\n",
      "  class2: 0.13%\n",
      "  class3: 0.85%\n",
      "  class4: 0.58%\n",
      "  class5: 0.21%\n",
      "\n",
      "Image 21:\n",
      "  class1: 0.03%\n",
      "  class2: 0.13%\n",
      "  class3: 0.70%\n",
      "  class4: 0.58%\n",
      "  class5: 0.02%\n",
      "\n",
      "Image 22:\n",
      "  class1: 0.00%\n",
      "  class2: 0.16%\n",
      "  class3: 0.64%\n",
      "  class4: 0.52%\n",
      "  class5: 0.01%\n",
      "\n",
      "Image 23:\n",
      "  class1: 0.00%\n",
      "  class2: 0.21%\n",
      "  class3: 0.52%\n",
      "  class4: 0.36%\n",
      "  class5: 0.01%\n",
      "\n",
      "Image 1: F,F,T,T,F\n",
      "Image 2: F,F,T,T,F\n",
      "Image 3: F,F,T,T,F\n",
      "Image 4: F,F,T,F,F\n",
      "Image 5: F,F,T,F,F\n",
      "Image 6: F,F,T,F,F\n",
      "Image 7: F,F,T,F,F\n",
      "Image 8: F,F,T,T,F\n",
      "Image 9: F,F,T,T,F\n",
      "Image 10: F,F,T,T,F\n",
      "Image 11: F,F,T,T,F\n",
      "Image 12: F,F,T,T,F\n",
      "Image 13: F,F,T,T,F\n",
      "Image 14: F,F,T,F,F\n",
      "Image 15: F,F,T,F,F\n",
      "Image 16: F,F,T,T,F\n",
      "Image 17: F,F,T,T,F\n",
      "Image 18: F,F,T,T,F\n",
      "Image 19: F,F,T,T,F\n",
      "Image 20: F,F,T,T,F\n",
      "Image 21: F,F,T,T,F\n",
      "Image 22: F,F,T,T,F\n",
      "Image 23: F,F,T,F,F\n",
      "Label 1: T = 0, F = 23\n",
      "Label 2: T = 0, F = 23\n",
      "Label 3: T = 23, F = 0\n",
      "Label 4: T = 16, F = 7\n",
      "Label 5: T = 0, F = 23\n"
     ]
    }
   ],
   "source": [
    "print(f'모델은 총 {num_classes}개의 클래스를 가지고 있습니다.')\n",
    "class_labels = []\n",
    "# 클래스 라벨 정의 (예: num_classes 개의 클래스)\n",
    "for i in range(num_classes):\n",
    "    class_labels.append(f'class{i+1}')\n",
    "\n",
    "# 예를 들어, num_classes가 3이라면 class_labels는 ['class1', 'cd lass2', 'class3']이 됩니다.\n",
    "\n",
    "\n",
    "# predictions 배열에서 각 입력에 대한 모든 클래스의 확률 출력\n",
    "for i, prediction in enumerate(smoothed_predictions):\n",
    "    print(f'Image {i+1}:')\n",
    "    for j, class_label in enumerate(class_labels):\n",
    "        print(f'  {class_label}: {prediction[j]:.2f}%')\n",
    "    print()  # 각 이미지의 예측 결과 사이에 공백 추가\n",
    "# 부드러운 예측 결과 출력\n",
    "\n",
    "\n",
    "print_predictions(smoothed_predictions, exercise_name, json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
