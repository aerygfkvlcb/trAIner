{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3268c649-11d2-41bc-b530-1fa7c1eedd9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7874 7874\n",
      "1691 1691\n",
      "1687 1687\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import cv2\n",
    "\n",
    "def process_dataset(root_folder):\n",
    "    image_paths = []\n",
    "    label_data = []\n",
    "\n",
    "    for roots, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                # 파일 이름 분석을 위해 숫자만 추출\n",
    "                prefix = file[0:3]\n",
    "\n",
    "                # 접두사에 따른 레이블 할당\n",
    "                label = prefix_to_label.get(prefix)\n",
    "\n",
    "                # 유효한 레이블이 있는 경우에만 리스트에 추가\n",
    "                if label is not None:\n",
    "                    image_paths.append(os.path.join(roots, file))\n",
    "                    label_data.append(label)\n",
    "\n",
    "    return image_paths, label_data\n",
    "\n",
    "\n",
    "def resize_img(image_paths):\n",
    "    images_resized = []  # 리사이즈된 이미지를 저장할 리스트\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)  # 각 이미지 경로로부터 이미지를 읽음\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR에서 RGB로 색상 변환\n",
    "        image_resized = cv2.resize(image, (128, 128))  # 이미지 리사이즈\n",
    "        images_resized.append(image_resized)  # 결과 리스트에 추가\n",
    "    images_resized = np.array(images_resized) / 255.0  # numpy 배열로 변환 및 정규화\n",
    "    return images_resized\n",
    "\n",
    "\n",
    "def shuffle_data(image_paths, label_data):\n",
    "    # 데이터와 레이블을 같이 섞어줍니다.\n",
    "    indices = np.arange(len(image_paths))\n",
    "    np.random.shuffle(indices)\n",
    "    shuffled_image_paths = np.array(image_paths)[indices]\n",
    "    shuffled_label_data = np.array(label_data)[indices]\n",
    "    return shuffled_image_paths, shuffled_label_data\n",
    "\n",
    "\n",
    "def multilabel_train_generator(image_paths, label_data, batch_size):\n",
    "    num_samples = len(image_paths)\n",
    "    while True:\n",
    "        # 데이터 셔플\n",
    "        image_paths, label_data = shuffle_data(image_paths, label_data)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "\n",
    "            # 배치 크기만큼 이미지와 레이블 데이터 로드 및 전처리\n",
    "            batch_image_paths = image_paths[offset:offset + batch_size]\n",
    "            batch_image_labels = label_data[offset:offset + batch_size]\n",
    "\n",
    "            batch_images = resize_img(batch_image_paths)\n",
    "            \n",
    "            for labels in batch_image_labels:\n",
    "                batch_labels.append(labels)\n",
    "\n",
    "            # 배치 데이터 반환\n",
    "            yield np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "\n",
    "def multilabel_test_generator(image_paths, label_data, batch_size):\n",
    "    num_samples = len(image_paths)\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "\n",
    "            # 배치 크기만큼 이미지와 레이블 데이터 로드 및 전처리\n",
    "            batch_image_paths = image_paths[offset:offset + batch_size]\n",
    "            batch_image_labels = label_data[offset:offset + batch_size]\n",
    "\n",
    "            batch_images = resize_img(batch_image_paths)\n",
    "            \n",
    "            for labels in batch_image_labels:\n",
    "                batch_labels.append(labels)\n",
    "\n",
    "            # 배치 데이터 반환\n",
    "            yield np.array(batch_images), np.array(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1de2f4-94f1-472e-80d9-362f6b178e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_path = [[0,0,0],[1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,1],[1,0,1],[1,1,1]]\n",
    "prefix = [f\"{i:03d}\" for i in range(505, 513)]\n",
    "prefix_to_label = dict(zip(prefix, last_path))\n",
    "# 각각의 데이터셋에 대해 함수를 호출\n",
    "train_folder = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\training'\n",
    "valid_folder = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\validation'\n",
    "test_folder = r'E:\\AI\\dataset_skeleton_sep\\face\\BicycleCrunch\\test'\n",
    "\n",
    "train_image_paths, train_label_data = process_dataset(train_folder)\n",
    "valid_image_paths, valid_label_data = process_dataset(valid_folder)\n",
    "test_image_paths, test_label_data = process_dataset(test_folder)\n",
    "print(len(train_image_paths), len(train_label_data))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = multilabel_train_generator(train_image_paths, train_label_data, batch_size)\n",
    "validation_generator = multilabel_test_generator(valid_image_paths, valid_label_data, batch_size)\n",
    "test_generator = multilabel_test_generator(test_image_paths, test_label_data, batch_size)\n",
    "\n",
    "# 모델 구성\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "for layer in base_model.layers:\n",
    "    base_model.trainable = False\n",
    "for layer in base_model.layers[-9:]:\n",
    "    base_model.trainable = True\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9343b4e-84c9-48c5-9f4d-7d061a7fc5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "246/246 [==============================] - 38s 125ms/step - loss: 0.6414 - accuracy: 0.2876 - val_loss: 0.7666 - val_accuracy: 0.1268\n",
      "Epoch 2/25\n",
      "246/246 [==============================] - 30s 120ms/step - loss: 0.5650 - accuracy: 0.3220 - val_loss: 0.7723 - val_accuracy: 0.1268\n",
      "Epoch 3/25\n",
      "246/246 [==============================] - 28s 112ms/step - loss: 0.5050 - accuracy: 0.3781 - val_loss: 0.7177 - val_accuracy: 0.1659\n",
      "Epoch 4/25\n",
      "246/246 [==============================] - 26s 108ms/step - loss: 0.4492 - accuracy: 0.4364 - val_loss: 0.6742 - val_accuracy: 0.1809\n",
      "Epoch 5/25\n",
      "246/246 [==============================] - 27s 111ms/step - loss: 0.3814 - accuracy: 0.4653 - val_loss: 0.5429 - val_accuracy: 0.4159\n",
      "Epoch 6/25\n",
      "246/246 [==============================] - 27s 111ms/step - loss: 0.3164 - accuracy: 0.4952 - val_loss: 0.6498 - val_accuracy: 0.4922\n",
      "Epoch 7/25\n",
      "246/246 [==============================] - 26s 107ms/step - loss: 0.2573 - accuracy: 0.5170 - val_loss: 0.7913 - val_accuracy: 0.4099\n",
      "Epoch 8/25\n",
      "246/246 [==============================] - 26s 104ms/step - loss: 0.2357 - accuracy: 0.5414 - val_loss: 1.0423 - val_accuracy: 0.6016\n",
      "Epoch 9/25\n",
      "246/246 [==============================] - 26s 106ms/step - loss: 0.1836 - accuracy: 0.5608 - val_loss: 0.6509 - val_accuracy: 0.3702\n",
      "Epoch 10/25\n",
      "246/246 [==============================] - 28s 112ms/step - loss: 0.1407 - accuracy: 0.5685 - val_loss: 0.5162 - val_accuracy: 0.5294\n",
      "Epoch 11/25\n",
      "246/246 [==============================] - 28s 113ms/step - loss: 0.1275 - accuracy: 0.5793 - val_loss: 0.5382 - val_accuracy: 0.4766\n",
      "Epoch 12/25\n",
      "246/246 [==============================] - 28s 113ms/step - loss: 0.0961 - accuracy: 0.5834 - val_loss: 0.4499 - val_accuracy: 0.4489\n",
      "Epoch 13/25\n",
      "246/246 [==============================] - 36s 147ms/step - loss: 0.1103 - accuracy: 0.6331 - val_loss: 0.4767 - val_accuracy: 0.4850\n",
      "Epoch 14/25\n",
      "246/246 [==============================] - 30s 122ms/step - loss: 0.0697 - accuracy: 0.6084 - val_loss: 0.6846 - val_accuracy: 0.4712\n",
      "Epoch 15/25\n",
      "246/246 [==============================] - 27s 110ms/step - loss: 0.0598 - accuracy: 0.5565 - val_loss: 0.5644 - val_accuracy: 0.5469\n",
      "Epoch 16/25\n",
      "246/246 [==============================] - 26s 106ms/step - loss: 0.0643 - accuracy: 0.5506 - val_loss: 0.5774 - val_accuracy: 0.4760\n",
      "Epoch 17/25\n",
      "246/246 [==============================] - 26s 106ms/step - loss: 0.0541 - accuracy: 0.5685 - val_loss: 0.4892 - val_accuracy: 0.5108\n",
      "Epoch 18/25\n",
      "246/246 [==============================] - 26s 106ms/step - loss: 0.0439 - accuracy: 0.5837 - val_loss: 0.6022 - val_accuracy: 0.4135\n",
      "Epoch 19/25\n",
      "246/246 [==============================] - 30s 122ms/step - loss: 0.0563 - accuracy: 0.5696 - val_loss: 0.5417 - val_accuracy: 0.4736\n",
      "Epoch 20/25\n",
      "246/246 [==============================] - 27s 108ms/step - loss: 0.0518 - accuracy: 0.6899 - val_loss: 0.4601 - val_accuracy: 0.5805\n",
      "Epoch 21/25\n",
      "246/246 [==============================] - 26s 106ms/step - loss: 0.0462 - accuracy: 0.5919 - val_loss: 0.5551 - val_accuracy: 0.4772\n",
      "Epoch 22/25\n",
      "246/246 [==============================] - 26s 105ms/step - loss: 0.0373 - accuracy: 0.5861 - val_loss: 0.8201 - val_accuracy: 0.3492\n",
      "Epoch 23/25\n",
      "246/246 [==============================] - 25s 103ms/step - loss: 0.0423 - accuracy: 0.5094 - val_loss: 0.7948 - val_accuracy: 0.4399\n",
      "Epoch 24/25\n",
      "246/246 [==============================] - 28s 112ms/step - loss: 0.0459 - accuracy: 0.5801 - val_loss: 0.5127 - val_accuracy: 0.4760\n",
      "Epoch 25/25\n",
      "246/246 [==============================] - 26s 107ms/step - loss: 0.0323 - accuracy: 0.5596 - val_loss: 0.5358 - val_accuracy: 0.4675\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0002),\n",
    "              loss=['binary_crossentropy'],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=len(train_image_paths) // batch_size,\n",
    "                    epochs=25,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=len(valid_image_paths) // batch_size,\n",
    "                    #callbacks=[earlystopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8bb863-cd24-4b49-be22-4c5ec423491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 24ms/step\n",
      "레이블 0의 정확도: 0.7949021932424422\n",
      "레이블 1의 정확도: 0.7931238885595732\n",
      "레이블 2의 정확도: 0.8772969768820391\n",
      "전체 정확도: 0.8217743528946848\n"
     ]
    }
   ],
   "source": [
    "train_image_resized = resize_img(train_image_paths)\n",
    "valid_image_resized = resize_img(valid_image_paths)\n",
    "test_image_resized = resize_img(test_image_paths)\n",
    "# 모델 예측\n",
    "predictions = model.predict(test_image_resized)\n",
    "\n",
    "# 임계값 설정 (예: 0.5)\n",
    "threshold = 0.5\n",
    "predictions_binary = (predictions > threshold).astype(int)\n",
    "\n",
    "# 각 레이블에 대한 정확도 계산\n",
    "accuracy_per_label = np.mean(predictions_binary == test_label_data, axis=0)\n",
    "\n",
    "# 각 레이블별 정확도 출력\n",
    "for i, accuracy in enumerate(accuracy_per_label):\n",
    "    print(f\"레이블 {i}의 정확도: {accuracy}\")\n",
    "\n",
    "# 전체 정확도도 여전히 중요할 수 있으므로, 이를 계산합니다.\n",
    "overall_accuracy = np.mean(predictions_binary == test_label_data)\n",
    "print(f\"전체 정확도: {overall_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2c51837-daef-4f3b-82a9-d3ef0939552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 2s 34ms/step\n",
      "레이블 0의 정확도: 0.44991108476585656\n",
      "레이블 1의 정확도: 0.3959691760521636\n",
      "레이블 2의 정확도: 0.5726141078838174\n",
      "전체 정확도: 0.47283145623394585\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋의 전체 샘플 수 계산\n",
    "test_steps = np.ceil(len(test_image_paths) / batch_size)\n",
    "\n",
    "predictions = model.predict(test_generator, steps=test_steps)\n",
    "\n",
    "# 임계값 설정\n",
    "threshold = 0.5\n",
    "predictions_binary = (predictions > threshold).astype(int)\n",
    "\n",
    "# 각 레이블에 대한 정확도 계산\n",
    "accuracy_per_label = np.mean(predictions_binary == test_label_data, axis=0)\n",
    "\n",
    "# 각 레이블별 정확도 출력\n",
    "for i, accuracy in enumerate(accuracy_per_label):\n",
    "    print(f\"레이블 {i}의 정확도: {accuracy}\")\n",
    "\n",
    "# 전체 정확도도 여전히 중요할 수 있으므로, 이를 계산합니다.\n",
    "overall_accuracy = np.mean(predictions_binary == test_label_data)\n",
    "print(f\"전체 정확도: {overall_accuracy}\")\n",
    "\n",
    "#model.save(r'E:\\AImodel\\models\\Face-KneePushup-multiLabel-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0df4df-3b3c-4f42-a3fd-85feba68a019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa30c4-dbcd-4500-8013-20e7108d1f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGPU",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
